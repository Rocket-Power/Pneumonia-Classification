{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Initial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5466419396212756211\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5718933504\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6065668296228390391\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")\n",
    "import tensorflow as tf\n",
    "# tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how to import this model \n",
    "# from tensorflow.keras.applications.resnet50v2 import ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: There are only 8 images per label here, so we're going to have to change what we do here \n",
    "# Confirmed that the # of images in the 3 folders sum to 5,856, which is the total number of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Paul_Backup\\paulj\\Pneumonia-Classification\\src\\test_notebooks\\paul_test\n",
      "Found 0 files belonging to 0 classes.\n",
      "Using 0 files for training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory D:\\Paul_Backup\\paulj\\Pneumonia-Classification\\src\\data\\\\NORMAL. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Use validation_split to get the training and validation data \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39mgetcwd())\n\u001b[1;32m----> 3\u001b[0m train_data \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mimage_dataset_from_directory(\n\u001b[0;32m      4\u001b[0m     \u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mPaul_Backup\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mpaulj\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mPneumonia-Classification\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39msrc\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mNORMAL\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     image_size\u001b[39m=\u001b[39;49m(\u001b[39m180\u001b[39;49m, \u001b[39m180\u001b[39;49m), \n\u001b[0;32m      6\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, \n\u001b[0;32m      7\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, \n\u001b[0;32m      8\u001b[0m     subset \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      9\u001b[0m     seed \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m\n\u001b[0;32m     10\u001b[0m )\n",
      "File \u001b[1;32md:\\Paul_Backup\\paulj\\Pneumonia-Classification\\.venv\\lib\\site-packages\\keras\\utils\\image_dataset.py:294\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m image_paths, labels \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39mget_training_or_validation_split(\n\u001b[0;32m    291\u001b[0m     image_paths, labels, validation_split, subset\n\u001b[0;32m    292\u001b[0m )\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m image_paths:\n\u001b[1;32m--> 294\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    295\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo images found in directory \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    296\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAllowed formats: \u001b[39m\u001b[39m{\u001b[39;00mALLOWLIST_FORMATS\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    299\u001b[0m dataset \u001b[39m=\u001b[39m paths_and_labels_to_dataset(\n\u001b[0;32m    300\u001b[0m     image_paths\u001b[39m=\u001b[39mimage_paths,\n\u001b[0;32m    301\u001b[0m     image_size\u001b[39m=\u001b[39mimage_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     crop_to_aspect_ratio\u001b[39m=\u001b[39mcrop_to_aspect_ratio,\n\u001b[0;32m    308\u001b[0m )\n\u001b[0;32m    309\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n",
      "\u001b[1;31mValueError\u001b[0m: No images found in directory D:\\Paul_Backup\\paulj\\Pneumonia-Classification\\src\\data\\\\NORMAL. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "# Use validation_split to get the training and validation data \n",
    "print(os.getcwd())\n",
    "train_data = keras.utils.image_dataset_from_directory(\n",
    "    'D:\\\\Paul_Backup\\\\paulj\\\\Pneumonia-Classification\\\\src\\\\data\\\\NORMAL',\n",
    "    image_size=(180, 180), \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    subset = 'training', \n",
    "    seed = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data: 79 files \n",
    "val_data = keras.utils.image_dataset_from_directory(\n",
    "    'initial_data/train',\n",
    "    image_size=(180, 180), \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    subset = 'validation', \n",
    "    seed = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data: 50 pneumonia and 50 normal images \n",
    "test_data = keras.utils.image_dataset_from_directory(\n",
    "    'initial_data/test',\n",
    "    image_size=(180, 180), \n",
    "    batch_size=32, \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial ResNet 50 Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build model \n",
    "def build_resnet50_model():\n",
    "    \n",
    "    # Define input shape for the model \n",
    "    inputs = keras.Input(shape = (180, 180, 3))\n",
    "    # Resnet 50 basemodel \n",
    "    base_model = ResNet50(input_shape = (180, 180, 3), weights = 'imagenet', include_top = False)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = keras.applications.resnet50.preprocess_input(inputs)\n",
    "    x = base_model(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    " \n",
    "    x = keras.layers.Dense(256, activation = 'relu')(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    outputs = keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model: \n",
    "resnet50_mod = build_resnet50_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit model \n",
    "def fit_model(model, train_set, validation_set):\n",
    "    \"\"\"Fit a model with the above stated criteria\"\"\"\n",
    "    # Set patience to 5 so it doesn't take too long to fit \n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    \n",
    "    model.fit(train_set, \n",
    "              validation_data = validation_set, \n",
    "              callbacks = [early_stopping], \n",
    "              epochs = 500)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model: \n",
    "# Started 12:18 pm; ended 12:55 pm --> 7 min to train \n",
    "# Best model: \n",
    "fitted_resnet50_mod = fit_model(resnet50_mod, train_data, val_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Inception V3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build model \n",
    "def build_inceptionV3_model():\n",
    "    \n",
    "    # Define input shape for the model \n",
    "    inputs = keras.Input(shape = (180, 180, 3))\n",
    "    # InceptionV3 base model \n",
    "    base_model = InceptionV3(input_shape = (180, 180, 3), weights = 'imagenet', include_top = False)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = keras.applications.resnet50.preprocess_input(inputs)\n",
    "    x = base_model(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    " \n",
    "    x = keras.layers.Dense(256, activation = 'relu')(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    outputs = keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model: \n",
    "inceptionV3_mod = build_inceptionV3_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model: \n",
    "# Started 12:48 pm; ended pm --> 9 min to train \n",
    "fitted_inceptionV3_mod = fit_model(inceptionV3_mod, train_data, val_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec691a19967da4d9de78f50ff8ff93098c175cbc1d9f273cfd57fe88badd9f1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
