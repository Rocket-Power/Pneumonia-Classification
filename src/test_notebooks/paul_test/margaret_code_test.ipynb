{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Initial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13511578285985094315\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5718933504\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1482443426090961942\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# run once\n",
    "# os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")\n",
    "import tensorflow as tf\n",
    "# tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how to import this model \n",
    "# from tensorflow.keras.applications.resnet50v2 import ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: There are only 8 images per label here, so we're going to have to change what we do here \n",
    "# Confirmed that the # of images in the 3 folders sum to 5,856, which is the total number of images \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLIT DATA RUN ONLY ONCE !!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data set into train, val, and test\n",
    "# just change the directory\n",
    "# ONLY RUN ONCE DO NOT RUN AGAIN\n",
    "# import splitfolders\n",
    "\n",
    "# splitfolders.ratio(\"D:\\Paul_Backup\\paulj\\Pneumonia-Classification\\src\\data\", output = \"D:\\Paul_Backup\\paulj\\Pneumonia-Classification\\src\\data_split\", seed = 1337, ratio = (0.6,0.2,0.2), group_prefix=None, move=False)\n",
    "\n",
    "# add code to check for data_split directory if exists delete and create again or don't run \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Paul_Backup\\paulj\\Pneumonia-Classification\\src\\test_notebooks\\paul_test\n",
      "Found 3512 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training data: 3512\n",
    "print(os.getcwd())\n",
    "train_data = keras.utils.image_dataset_from_directory(\n",
    "    'D:\\\\Paul_Backup\\\\paulj\\\\Pneumonia-Classification\\\\src\\\\data_split\\\\train',\n",
    "    image_size=(256, 256), \n",
    "    batch_size=32, \n",
    "    seed = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1170 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Validation data: 1170\n",
    "val_data = keras.utils.image_dataset_from_directory(\n",
    "    'D:\\\\Paul_Backup\\\\paulj\\\\Pneumonia-Classification\\\\src\\\\data_split\\\\val',\n",
    "    image_size=(256, 256), \n",
    "    batch_size=32, \n",
    "    seed = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1174 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test data: 1174\n",
    "test_data = keras.utils.image_dataset_from_directory(\n",
    "    'D:\\\\Paul_Backup\\\\paulj\\\\Pneumonia-Classification\\\\src\\\\data_split\\\\test',\n",
    "    image_size=(256, 256), \n",
    "    batch_size=32, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltrain = train_data.concatenate(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(fulltrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=147>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.experimental.cardinality(fulltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=37>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.experimental.cardinality(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=110>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.experimental.cardinality(train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial ResNet 50 Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build model \n",
    "def build_resnet50_model(drop_rate):\n",
    "    \n",
    "    # Define input shape for the model \n",
    "    inputs = keras.Input(shape = (256, 256, 3))\n",
    "    # Resnet 50 basemodel \n",
    "    base_model = ResNet50(input_shape = (256, 256, 3), weights = 'imagenet', include_top = False)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = keras.applications.resnet50.preprocess_input(inputs)\n",
    "    x = base_model(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    " \n",
    "    x = keras.layers.Dense(256, activation = 'relu')(x)\n",
    "    x = keras.layers.Dropout(drop_rate)(x)\n",
    "    outputs = keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model: \n",
    "resnet50_mod = build_resnet50_model(drop_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit model \n",
    "def fit_model(model, train_set, validation_set):\n",
    "    \"\"\"Fit a model with the above stated criteria\"\"\"\n",
    "    # Set patience to 5 so it doesn't take too long to fit \n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    \n",
    "    model.fit(train_set, \n",
    "              validation_data = validation_set, \n",
    "              callbacks = [early_stopping], \n",
    "              epochs = 500)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 63ms/step - loss: 4.1018 - accuracy: 0.9052 - val_loss: 0.2027 - val_accuracy: 0.9462\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3226 - accuracy: 0.9462 - val_loss: 0.2598 - val_accuracy: 0.9547\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2105 - accuracy: 0.9655 - val_loss: 0.1572 - val_accuracy: 0.9538\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1836 - accuracy: 0.9690 - val_loss: 0.2464 - val_accuracy: 0.9581\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1050 - accuracy: 0.9778 - val_loss: 0.1235 - val_accuracy: 0.9692\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1078 - accuracy: 0.9795 - val_loss: 0.2403 - val_accuracy: 0.9650\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0806 - accuracy: 0.9860 - val_loss: 0.4862 - val_accuracy: 0.9504\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0515 - accuracy: 0.9875 - val_loss: 0.2040 - val_accuracy: 0.9709\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0689 - accuracy: 0.9875 - val_loss: 0.9463 - val_accuracy: 0.9145\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0530 - accuracy: 0.9903 - val_loss: 0.2728 - val_accuracy: 0.9632\n"
     ]
    }
   ],
   "source": [
    "# Fit the model: \n",
    "# Started 12:18 pm; ended 12:55 pm --> 37 min to train \n",
    "# Best model: \n",
    "fitted_resnet50_mod = fit_model(resnet50_mod, train_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "110/110 [==============================] - 16s 108ms/step - loss: 8.8018 - accuracy: 0.9080 - val_loss: 0.2947 - val_accuracy: 0.9675\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.5402 - accuracy: 0.9462 - val_loss: 1.3629 - val_accuracy: 0.8880\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.3069 - accuracy: 0.9644 - val_loss: 0.3733 - val_accuracy: 0.9675\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2092 - accuracy: 0.9741 - val_loss: 0.5942 - val_accuracy: 0.9607\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2054 - accuracy: 0.9775 - val_loss: 0.3031 - val_accuracy: 0.9641\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0735 - accuracy: 0.9869 - val_loss: 0.2709 - val_accuracy: 0.9658\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0794 - accuracy: 0.9903 - val_loss: 0.3105 - val_accuracy: 0.9692\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0312 - accuracy: 0.9940 - val_loss: 0.2289 - val_accuracy: 0.9718\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0460 - accuracy: 0.9940 - val_loss: 0.2715 - val_accuracy: 0.9752\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0821 - accuracy: 0.9929 - val_loss: 0.3610 - val_accuracy: 0.9667\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0222 - accuracy: 0.9963 - val_loss: 0.3322 - val_accuracy: 0.9692\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0414 - accuracy: 0.9949 - val_loss: 0.3940 - val_accuracy: 0.9744\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0367 - accuracy: 0.9957 - val_loss: 0.3321 - val_accuracy: 0.9658\n",
      "37/37 [==============================] - 3s 69ms/step - loss: 0.3234 - accuracy: 0.9719\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 15s 104ms/step - loss: 8.3572 - accuracy: 0.9129 - val_loss: 4.4523 - val_accuracy: 0.8137\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 1.2102 - accuracy: 0.9485 - val_loss: 2.0935 - val_accuracy: 0.9145\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2996 - accuracy: 0.9727 - val_loss: 0.1382 - val_accuracy: 0.9718\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2712 - accuracy: 0.9738 - val_loss: 0.1962 - val_accuracy: 0.9709\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2316 - accuracy: 0.9761 - val_loss: 0.5756 - val_accuracy: 0.9590\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1331 - accuracy: 0.9843 - val_loss: 0.6155 - val_accuracy: 0.9615\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1515 - accuracy: 0.9838 - val_loss: 0.2824 - val_accuracy: 0.9735\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0337 - accuracy: 0.9926 - val_loss: 0.3203 - val_accuracy: 0.9692\n",
      "37/37 [==============================] - 3s 66ms/step - loss: 0.2486 - accuracy: 0.9727\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 16s 106ms/step - loss: 9.4131 - accuracy: 0.9100 - val_loss: 2.1901 - val_accuracy: 0.9291\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.8793 - accuracy: 0.9533 - val_loss: 1.8873 - val_accuracy: 0.9188\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.5204 - accuracy: 0.9667 - val_loss: 0.2725 - val_accuracy: 0.9624\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.3320 - accuracy: 0.9701 - val_loss: 0.2990 - val_accuracy: 0.9692\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1329 - accuracy: 0.9835 - val_loss: 0.3461 - val_accuracy: 0.9692\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1923 - accuracy: 0.9804 - val_loss: 0.4142 - val_accuracy: 0.9692\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1526 - accuracy: 0.9892 - val_loss: 0.5116 - val_accuracy: 0.9684\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1088 - accuracy: 0.9903 - val_loss: 0.3039 - val_accuracy: 0.9744\n",
      "37/37 [==============================] - 3s 67ms/step - loss: 0.2709 - accuracy: 0.9753\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 17s 122ms/step - loss: 9.5041 - accuracy: 0.9117 - val_loss: 0.9223 - val_accuracy: 0.9556\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 1.1073 - accuracy: 0.9579 - val_loss: 0.4103 - val_accuracy: 0.9598\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.5601 - accuracy: 0.9621 - val_loss: 0.3921 - val_accuracy: 0.9624\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3722 - accuracy: 0.9738 - val_loss: 2.2246 - val_accuracy: 0.8889\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2619 - accuracy: 0.9795 - val_loss: 0.3395 - val_accuracy: 0.9650\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2222 - accuracy: 0.9821 - val_loss: 0.6204 - val_accuracy: 0.9641\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1869 - accuracy: 0.9852 - val_loss: 0.5718 - val_accuracy: 0.9607\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1350 - accuracy: 0.9889 - val_loss: 0.6432 - val_accuracy: 0.9726\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1526 - accuracy: 0.9892 - val_loss: 0.7284 - val_accuracy: 0.9709\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0614 - accuracy: 0.9937 - val_loss: 0.9238 - val_accuracy: 0.9658\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 0.7759 - accuracy: 0.9736\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 15s 108ms/step - loss: 5.9207 - accuracy: 0.8830 - val_loss: 0.1468 - val_accuracy: 0.9615\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2371 - accuracy: 0.9507 - val_loss: 0.1765 - val_accuracy: 0.9453\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1863 - accuracy: 0.9587 - val_loss: 0.1405 - val_accuracy: 0.9615\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1184 - accuracy: 0.9695 - val_loss: 0.1429 - val_accuracy: 0.9667\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0942 - accuracy: 0.9778 - val_loss: 0.1859 - val_accuracy: 0.9692\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0960 - accuracy: 0.9809 - val_loss: 0.1753 - val_accuracy: 0.9667\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.0790 - accuracy: 0.9849 - val_loss: 0.2213 - val_accuracy: 0.9650\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0498 - accuracy: 0.9897 - val_loss: 0.1692 - val_accuracy: 0.9701\n",
      "37/37 [==============================] - 3s 66ms/step - loss: 0.1219 - accuracy: 0.9779\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 16s 111ms/step - loss: 7.6124 - accuracy: 0.9095 - val_loss: 0.2739 - val_accuracy: 0.9701\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.5434 - accuracy: 0.9490 - val_loss: 0.1419 - val_accuracy: 0.9564\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2860 - accuracy: 0.9630 - val_loss: 0.2747 - val_accuracy: 0.9496\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2145 - accuracy: 0.9695 - val_loss: 0.2787 - val_accuracy: 0.9641\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.2819 - accuracy: 0.9690 - val_loss: 0.2671 - val_accuracy: 0.9692\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1221 - accuracy: 0.9823 - val_loss: 0.4028 - val_accuracy: 0.9658\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.0789 - accuracy: 0.9880 - val_loss: 0.2533 - val_accuracy: 0.9667\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.2551 - accuracy: 0.9693\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 16s 109ms/step - loss: 14.0335 - accuracy: 0.9072 - val_loss: 1.7631 - val_accuracy: 0.9641\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 1.6677 - accuracy: 0.9590 - val_loss: 0.3626 - val_accuracy: 0.9650\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.4910 - accuracy: 0.9596 - val_loss: 0.8941 - val_accuracy: 0.9427\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2040 - accuracy: 0.9741 - val_loss: 0.2607 - val_accuracy: 0.9726\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.3024 - accuracy: 0.9775 - val_loss: 0.4073 - val_accuracy: 0.9667\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1802 - accuracy: 0.9829 - val_loss: 0.2498 - val_accuracy: 0.9667\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1312 - accuracy: 0.9846 - val_loss: 1.2006 - val_accuracy: 0.9487\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2567 - accuracy: 0.9815 - val_loss: 0.4514 - val_accuracy: 0.9675\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0636 - accuracy: 0.9935 - val_loss: 0.4955 - val_accuracy: 0.9607\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0920 - accuracy: 0.9892 - val_loss: 0.5938 - val_accuracy: 0.9709\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1353 - accuracy: 0.9903 - val_loss: 1.1992 - val_accuracy: 0.9282\n",
      "37/37 [==============================] - 3s 69ms/step - loss: 1.2329 - accuracy: 0.9165\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 15s 108ms/step - loss: 6.1918 - accuracy: 0.9083 - val_loss: 0.2020 - val_accuracy: 0.9538\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.3471 - accuracy: 0.9530 - val_loss: 0.1332 - val_accuracy: 0.9641\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.3261 - accuracy: 0.9584 - val_loss: 0.2318 - val_accuracy: 0.9692\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1901 - accuracy: 0.9715 - val_loss: 0.1694 - val_accuracy: 0.9701\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1268 - accuracy: 0.9781 - val_loss: 0.4198 - val_accuracy: 0.9564\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1096 - accuracy: 0.9818 - val_loss: 0.1896 - val_accuracy: 0.9684\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0569 - accuracy: 0.9880 - val_loss: 0.2452 - val_accuracy: 0.9684\n",
      "37/37 [==============================] - 3s 66ms/step - loss: 0.2247 - accuracy: 0.9659\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 16s 108ms/step - loss: 6.1831 - accuracy: 0.9114 - val_loss: 0.6396 - val_accuracy: 0.9085\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3368 - accuracy: 0.9533 - val_loss: 0.3079 - val_accuracy: 0.9479\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2689 - accuracy: 0.9607 - val_loss: 0.1763 - val_accuracy: 0.9513\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2975 - accuracy: 0.9732 - val_loss: 0.2360 - val_accuracy: 0.9632\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1523 - accuracy: 0.9784 - val_loss: 0.2885 - val_accuracy: 0.9496\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1261 - accuracy: 0.9798 - val_loss: 0.1857 - val_accuracy: 0.9709\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1010 - accuracy: 0.9863 - val_loss: 0.2498 - val_accuracy: 0.9667\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0557 - accuracy: 0.9889 - val_loss: 0.1877 - val_accuracy: 0.9718\n",
      "37/37 [==============================] - 3s 67ms/step - loss: 0.1587 - accuracy: 0.9693\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 16s 107ms/step - loss: 6.9509 - accuracy: 0.9183 - val_loss: 2.0568 - val_accuracy: 0.8154\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.4801 - accuracy: 0.9493 - val_loss: 0.1777 - val_accuracy: 0.9658\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2253 - accuracy: 0.9587 - val_loss: 2.8043 - val_accuracy: 0.7812\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3606 - accuracy: 0.9638 - val_loss: 0.5191 - val_accuracy: 0.9590\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1319 - accuracy: 0.9772 - val_loss: 0.3793 - val_accuracy: 0.9530\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1335 - accuracy: 0.9772 - val_loss: 0.1445 - val_accuracy: 0.9692\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1063 - accuracy: 0.9852 - val_loss: 0.1902 - val_accuracy: 0.9641\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0388 - accuracy: 0.9912 - val_loss: 1.3526 - val_accuracy: 0.9043\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0585 - accuracy: 0.9906 - val_loss: 0.2945 - val_accuracy: 0.9718\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0791 - accuracy: 0.9878 - val_loss: 0.2880 - val_accuracy: 0.9684\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0440 - accuracy: 0.9906 - val_loss: 0.3384 - val_accuracy: 0.9684\n",
      "37/37 [==============================] - 3s 66ms/step - loss: 0.3320 - accuracy: 0.9719\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 15s 104ms/step - loss: 9.8850 - accuracy: 0.9092 - val_loss: 0.9593 - val_accuracy: 0.9103\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.3439 - accuracy: 0.9556 - val_loss: 0.4157 - val_accuracy: 0.9419\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.3326 - accuracy: 0.9573 - val_loss: 0.3469 - val_accuracy: 0.9590\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1987 - accuracy: 0.9687 - val_loss: 1.4033 - val_accuracy: 0.8547\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1735 - accuracy: 0.9738 - val_loss: 0.2159 - val_accuracy: 0.9675\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1370 - accuracy: 0.9784 - val_loss: 0.1232 - val_accuracy: 0.9701\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0864 - accuracy: 0.9838 - val_loss: 0.4726 - val_accuracy: 0.9547\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1019 - accuracy: 0.9872 - val_loss: 0.3699 - val_accuracy: 0.9701\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0536 - accuracy: 0.9889 - val_loss: 0.2126 - val_accuracy: 0.9692\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0618 - accuracy: 0.9878 - val_loss: 0.3875 - val_accuracy: 0.9718\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.0471 - accuracy: 0.9920 - val_loss: 0.3306 - val_accuracy: 0.9667\n",
      "37/37 [==============================] - 3s 66ms/step - loss: 0.2862 - accuracy: 0.9727\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 15s 104ms/step - loss: 7.4504 - accuracy: 0.9123 - val_loss: 0.6553 - val_accuracy: 0.9658\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.8135 - accuracy: 0.9513 - val_loss: 0.1643 - val_accuracy: 0.9598\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.3348 - accuracy: 0.9590 - val_loss: 0.3635 - val_accuracy: 0.9607\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2631 - accuracy: 0.9712 - val_loss: 0.1669 - val_accuracy: 0.9667\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2321 - accuracy: 0.9735 - val_loss: 0.2748 - val_accuracy: 0.9692\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1765 - accuracy: 0.9798 - val_loss: 0.3258 - val_accuracy: 0.9650\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0917 - accuracy: 0.9838 - val_loss: 0.4098 - val_accuracy: 0.9701\n",
      "37/37 [==============================] - 3s 66ms/step - loss: 0.2787 - accuracy: 0.9710\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 15s 104ms/step - loss: 8.7233 - accuracy: 0.9154 - val_loss: 0.2767 - val_accuracy: 0.9615\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.5970 - accuracy: 0.9459 - val_loss: 0.2678 - val_accuracy: 0.9598\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.6002 - accuracy: 0.9536 - val_loss: 0.2929 - val_accuracy: 0.9521\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.3440 - accuracy: 0.9644 - val_loss: 0.1920 - val_accuracy: 0.9641\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1975 - accuracy: 0.9781 - val_loss: 0.4362 - val_accuracy: 0.9496\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1569 - accuracy: 0.9806 - val_loss: 0.3198 - val_accuracy: 0.9598\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1267 - accuracy: 0.9823 - val_loss: 0.2344 - val_accuracy: 0.9684\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1415 - accuracy: 0.9829 - val_loss: 0.4900 - val_accuracy: 0.9684\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 12s 104ms/step - loss: 0.1565 - accuracy: 0.9846 - val_loss: 0.3794 - val_accuracy: 0.9735\n",
      "37/37 [==============================] - 3s 72ms/step - loss: 0.3355 - accuracy: 0.9753\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 17s 109ms/step - loss: 6.4909 - accuracy: 0.9035 - val_loss: 0.1577 - val_accuracy: 0.9590\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.4741 - accuracy: 0.9405 - val_loss: 0.5258 - val_accuracy: 0.9256\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.4905 - accuracy: 0.9522 - val_loss: 0.1721 - val_accuracy: 0.9718\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2563 - accuracy: 0.9684 - val_loss: 0.2822 - val_accuracy: 0.9060\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2388 - accuracy: 0.9690 - val_loss: 0.3912 - val_accuracy: 0.9632\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1555 - accuracy: 0.9758 - val_loss: 0.1511 - val_accuracy: 0.9709\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1266 - accuracy: 0.9798 - val_loss: 0.1729 - val_accuracy: 0.9718\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1002 - accuracy: 0.9843 - val_loss: 0.2377 - val_accuracy: 0.9684\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1610 - accuracy: 0.9835 - val_loss: 0.5811 - val_accuracy: 0.9607\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.0834 - accuracy: 0.9852 - val_loss: 0.2946 - val_accuracy: 0.9709\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 12s 103ms/step - loss: 0.1667 - accuracy: 0.9858 - val_loss: 0.3549 - val_accuracy: 0.9590\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.2311 - accuracy: 0.9676\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 17s 115ms/step - loss: 5.7180 - accuracy: 0.9132 - val_loss: 0.2619 - val_accuracy: 0.9581\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 12s 103ms/step - loss: 0.4720 - accuracy: 0.9485 - val_loss: 0.1893 - val_accuracy: 0.9658\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 12s 103ms/step - loss: 0.4056 - accuracy: 0.9530 - val_loss: 0.1838 - val_accuracy: 0.9615\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 12s 103ms/step - loss: 0.2505 - accuracy: 0.9675 - val_loss: 0.3270 - val_accuracy: 0.9684\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 12s 103ms/step - loss: 0.1728 - accuracy: 0.9721 - val_loss: 0.2198 - val_accuracy: 0.9667\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 12s 103ms/step - loss: 0.1620 - accuracy: 0.9804 - val_loss: 0.3564 - val_accuracy: 0.9615\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 12s 103ms/step - loss: 0.1001 - accuracy: 0.9832 - val_loss: 0.3880 - val_accuracy: 0.9624\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 12s 103ms/step - loss: 0.0974 - accuracy: 0.9835 - val_loss: 0.2896 - val_accuracy: 0.9658\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.1938 - accuracy: 0.9727\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 18s 113ms/step - loss: 6.6879 - accuracy: 0.9015 - val_loss: 0.1984 - val_accuracy: 0.9530\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.3457 - accuracy: 0.9394 - val_loss: 0.0900 - val_accuracy: 0.9667\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3621 - accuracy: 0.9559 - val_loss: 0.1533 - val_accuracy: 0.9650\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1716 - accuracy: 0.9690 - val_loss: 0.2055 - val_accuracy: 0.9607\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2754 - accuracy: 0.9681 - val_loss: 0.2034 - val_accuracy: 0.9632\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1308 - accuracy: 0.9752 - val_loss: 0.1959 - val_accuracy: 0.9658\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1430 - accuracy: 0.9744 - val_loss: 0.1634 - val_accuracy: 0.9650\n",
      "37/37 [==============================] - 3s 68ms/step - loss: 0.1353 - accuracy: 0.9685\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 16s 108ms/step - loss: 10.0447 - accuracy: 0.9092 - val_loss: 0.8471 - val_accuracy: 0.9632\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 1.1353 - accuracy: 0.9516 - val_loss: 0.7377 - val_accuracy: 0.9282\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.4390 - accuracy: 0.9599 - val_loss: 0.2438 - val_accuracy: 0.9624\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2872 - accuracy: 0.9678 - val_loss: 1.4973 - val_accuracy: 0.8786\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2752 - accuracy: 0.9701 - val_loss: 0.7626 - val_accuracy: 0.9607\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3044 - accuracy: 0.9764 - val_loss: 0.2519 - val_accuracy: 0.9692\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2306 - accuracy: 0.9809 - val_loss: 0.3915 - val_accuracy: 0.9607\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2517 - accuracy: 0.9795 - val_loss: 0.4596 - val_accuracy: 0.9675\n",
      "37/37 [==============================] - 3s 68ms/step - loss: 0.3218 - accuracy: 0.9719\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 17s 109ms/step - loss: 5.9990 - accuracy: 0.9077 - val_loss: 0.1074 - val_accuracy: 0.9650\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.4047 - accuracy: 0.9448 - val_loss: 0.2429 - val_accuracy: 0.9590\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.3022 - accuracy: 0.9587 - val_loss: 0.6448 - val_accuracy: 0.9410\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2773 - accuracy: 0.9621 - val_loss: 0.4402 - val_accuracy: 0.9513\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2328 - accuracy: 0.9658 - val_loss: 0.1711 - val_accuracy: 0.9658\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1238 - accuracy: 0.9775 - val_loss: 0.7999 - val_accuracy: 0.9316\n",
      "37/37 [==============================] - 3s 68ms/step - loss: 0.8928 - accuracy: 0.9259\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 17s 109ms/step - loss: 7.8240 - accuracy: 0.9095 - val_loss: 0.4013 - val_accuracy: 0.9590\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.5508 - accuracy: 0.9431 - val_loss: 1.2010 - val_accuracy: 0.8735\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3307 - accuracy: 0.9536 - val_loss: 0.2221 - val_accuracy: 0.9641\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2057 - accuracy: 0.9667 - val_loss: 0.1278 - val_accuracy: 0.9650\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1695 - accuracy: 0.9747 - val_loss: 0.0866 - val_accuracy: 0.9632\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1400 - accuracy: 0.9710 - val_loss: 0.1395 - val_accuracy: 0.9709\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1295 - accuracy: 0.9764 - val_loss: 0.2621 - val_accuracy: 0.9684\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0713 - accuracy: 0.9852 - val_loss: 0.2390 - val_accuracy: 0.9650\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0861 - accuracy: 0.9852 - val_loss: 0.2980 - val_accuracy: 0.9632\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0727 - accuracy: 0.9852 - val_loss: 0.3053 - val_accuracy: 0.9547\n",
      "37/37 [==============================] - 3s 68ms/step - loss: 0.3283 - accuracy: 0.9489\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 17s 109ms/step - loss: 5.6915 - accuracy: 0.9003 - val_loss: 0.7117 - val_accuracy: 0.9350\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.4167 - accuracy: 0.9285 - val_loss: 0.1043 - val_accuracy: 0.9615\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3219 - accuracy: 0.9453 - val_loss: 0.1090 - val_accuracy: 0.9692\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1712 - accuracy: 0.9596 - val_loss: 0.1411 - val_accuracy: 0.9607\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1811 - accuracy: 0.9618 - val_loss: 0.1805 - val_accuracy: 0.9667\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1632 - accuracy: 0.9687 - val_loss: 0.0993 - val_accuracy: 0.9701\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2091 - accuracy: 0.9692 - val_loss: 0.2031 - val_accuracy: 0.9709\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1363 - accuracy: 0.9707 - val_loss: 0.2396 - val_accuracy: 0.9564\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0976 - accuracy: 0.9778 - val_loss: 0.1541 - val_accuracy: 0.9735\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1536 - accuracy: 0.9735 - val_loss: 0.2014 - val_accuracy: 0.9709\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0622 - accuracy: 0.9821 - val_loss: 0.2469 - val_accuracy: 0.9667\n",
      "37/37 [==============================] - 3s 67ms/step - loss: 0.2109 - accuracy: 0.9719\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 16s 109ms/step - loss: 7.1032 - accuracy: 0.8881 - val_loss: 0.3186 - val_accuracy: 0.8966\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3623 - accuracy: 0.9356 - val_loss: 0.1065 - val_accuracy: 0.9650\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2616 - accuracy: 0.9436 - val_loss: 0.1700 - val_accuracy: 0.9650\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1909 - accuracy: 0.9650 - val_loss: 0.1144 - val_accuracy: 0.9667\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1608 - accuracy: 0.9618 - val_loss: 0.2304 - val_accuracy: 0.9667\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1607 - accuracy: 0.9721 - val_loss: 0.1766 - val_accuracy: 0.9667\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1340 - accuracy: 0.9710 - val_loss: 0.1616 - val_accuracy: 0.9718\n",
      "37/37 [==============================] - 3s 68ms/step - loss: 0.1184 - accuracy: 0.9710\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 18s 110ms/step - loss: 7.8393 - accuracy: 0.9080 - val_loss: 0.4904 - val_accuracy: 0.9547\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.6217 - accuracy: 0.9408 - val_loss: 0.5928 - val_accuracy: 0.9453\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.4593 - accuracy: 0.9522 - val_loss: 0.6627 - val_accuracy: 0.9410\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2777 - accuracy: 0.9630 - val_loss: 0.1659 - val_accuracy: 0.9658\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2690 - accuracy: 0.9613 - val_loss: 0.1629 - val_accuracy: 0.9667\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1940 - accuracy: 0.9721 - val_loss: 0.3331 - val_accuracy: 0.9624\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1396 - accuracy: 0.9712 - val_loss: 0.6806 - val_accuracy: 0.9214\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1942 - accuracy: 0.9764 - val_loss: 0.3116 - val_accuracy: 0.9615\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.0846 - accuracy: 0.9826 - val_loss: 0.3571 - val_accuracy: 0.9607\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1121 - accuracy: 0.9821 - val_loss: 0.2392 - val_accuracy: 0.9709\n",
      "37/37 [==============================] - 3s 68ms/step - loss: 0.1543 - accuracy: 0.9736\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 17s 110ms/step - loss: 8.9697 - accuracy: 0.8958 - val_loss: 1.8915 - val_accuracy: 0.8137\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3691 - accuracy: 0.9325 - val_loss: 0.4527 - val_accuracy: 0.9239\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3226 - accuracy: 0.9479 - val_loss: 0.1320 - val_accuracy: 0.9615\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2497 - accuracy: 0.9539 - val_loss: 0.1613 - val_accuracy: 0.9632\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2164 - accuracy: 0.9581 - val_loss: 0.1387 - val_accuracy: 0.9650\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1755 - accuracy: 0.9675 - val_loss: 0.1541 - val_accuracy: 0.9667\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1091 - accuracy: 0.9741 - val_loss: 0.1550 - val_accuracy: 0.9632\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1200 - accuracy: 0.9710 - val_loss: 0.1576 - val_accuracy: 0.9701\n",
      "37/37 [==============================] - 3s 67ms/step - loss: 0.1806 - accuracy: 0.9625\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 17s 109ms/step - loss: 5.3959 - accuracy: 0.9055 - val_loss: 0.1410 - val_accuracy: 0.9530\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.3068 - accuracy: 0.9382 - val_loss: 0.2161 - val_accuracy: 0.9521\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.4242 - accuracy: 0.9428 - val_loss: 0.1375 - val_accuracy: 0.9624\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2936 - accuracy: 0.9496 - val_loss: 0.4215 - val_accuracy: 0.9479\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1552 - accuracy: 0.9667 - val_loss: 0.1281 - val_accuracy: 0.9675\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1343 - accuracy: 0.9738 - val_loss: 0.2080 - val_accuracy: 0.9632\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1802 - accuracy: 0.9718 - val_loss: 0.1647 - val_accuracy: 0.9675\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1057 - accuracy: 0.9784 - val_loss: 0.3890 - val_accuracy: 0.9598\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1249 - accuracy: 0.9789 - val_loss: 0.2756 - val_accuracy: 0.9650\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.0942 - accuracy: 0.9809 - val_loss: 0.1613 - val_accuracy: 0.9701\n",
      "37/37 [==============================] - 3s 68ms/step - loss: 0.1250 - accuracy: 0.9770\n"
     ]
    }
   ],
   "source": [
    "drop_rate = 0.02\n",
    "result_dict = {}\n",
    "while drop_rate <= 0.5:\n",
    "    resnet50_mod = build_resnet50_model(drop_rate)\n",
    "    fitted_resnet50_mod = fit_model(resnet50_mod, train_data, val_data)\n",
    "    result_dict[drop_rate] = fitted_resnet50_mod.evaluate(test_data)\n",
    "    drop_rate += 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.02: [0.32337895035743713, 0.9718909859657288],\n",
       " 0.04: [0.24860438704490662, 0.9727427363395691],\n",
       " 0.06: [0.27088576555252075, 0.9752981066703796],\n",
       " 0.08: [0.7759113907814026, 0.9735945463180542],\n",
       " 0.1: [0.12189581245183945, 0.9778534770011902],\n",
       " 0.12000000000000001: [0.25513723492622375, 0.9693356156349182],\n",
       " 0.14: [1.2328615188598633, 0.9165247082710266],\n",
       " 0.16: [0.2246522456407547, 0.9659284353256226],\n",
       " 0.18: [0.15865661203861237, 0.9693356156349182],\n",
       " 0.19999999999999998: [0.3319864273071289, 0.9718909859657288],\n",
       " 0.21999999999999997: [0.2862241268157959, 0.9727427363395691],\n",
       " 0.23999999999999996: [0.278745174407959, 0.9710391759872437],\n",
       " 0.25999999999999995: [0.3354964554309845, 0.9752981066703796],\n",
       " 0.27999999999999997: [0.2311326265335083, 0.9676320552825928],\n",
       " 0.3: [0.19375668466091156, 0.9727427363395691],\n",
       " 0.32: [0.13530941307544708, 0.9684838056564331],\n",
       " 0.34: [0.3218041658401489, 0.9718909859657288],\n",
       " 0.36000000000000004: [0.8927669525146484, 0.9258943796157837],\n",
       " 0.38000000000000006: [0.328285813331604, 0.9488926529884338],\n",
       " 0.4000000000000001: [0.21087893843650818, 0.9718909859657288],\n",
       " 0.4200000000000001: [0.1184234619140625, 0.9710391759872437],\n",
       " 0.4400000000000001: [0.15431852638721466, 0.9735945463180542],\n",
       " 0.46000000000000013: [0.18055038154125214, 0.9625213146209717],\n",
       " 0.48000000000000015: [0.1250496804714203, 0.9770017266273499]}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 2s 40ms/step - loss: 0.2985 - accuracy: 0.9719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2985367178916931, 0.9718909859657288]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_resnet50_mod.evaluate(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Inception V3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build model \n",
    "def build_inceptionV3_model(drop_rate):\n",
    "    \n",
    "    # Define input shape for the model \n",
    "    inputs = keras.Input(shape = (180, 180, 3))\n",
    "    # InceptionV3 base model \n",
    "    base_model = InceptionV3(input_shape = (180, 180, 3), weights = 'imagenet', include_top = False)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = keras.applications.resnet50.preprocess_input(inputs)\n",
    "    x = base_model(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    " \n",
    "    x = keras.layers.Dense(256, activation = 'relu')(x)\n",
    "    x = keras.layers.Dropout(drop_rate)(x)\n",
    "    outputs = keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Build the model: \n",
    "inceptionV3_mod = build_inceptionV3_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 54ms/step - loss: 45.4147 - accuracy: 0.8260 - val_loss: 0.2524 - val_accuracy: 0.9162\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 3.0751 - accuracy: 0.8331 - val_loss: 0.6364 - val_accuracy: 0.8940\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 1.3997 - accuracy: 0.8485 - val_loss: 0.4082 - val_accuracy: 0.9051\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 1.0579 - accuracy: 0.8730 - val_loss: 0.2310 - val_accuracy: 0.9385\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.6529 - accuracy: 0.8682 - val_loss: 0.3089 - val_accuracy: 0.9239\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.6720 - accuracy: 0.8687 - val_loss: 0.2724 - val_accuracy: 0.9419\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.5545 - accuracy: 0.8767 - val_loss: 0.2505 - val_accuracy: 0.9419\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.4449 - accuracy: 0.8909 - val_loss: 0.2053 - val_accuracy: 0.9385\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.6156 - accuracy: 0.8978 - val_loss: 0.4596 - val_accuracy: 0.8709\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.4289 - accuracy: 0.8969 - val_loss: 0.1900 - val_accuracy: 0.9436\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.2647 - accuracy: 0.9038 - val_loss: 0.2303 - val_accuracy: 0.9487\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.4853 - accuracy: 0.9018 - val_loss: 0.1857 - val_accuracy: 0.9436\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3147 - accuracy: 0.9160 - val_loss: 0.3613 - val_accuracy: 0.9120\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.3198 - accuracy: 0.9157 - val_loss: 0.5688 - val_accuracy: 0.8769\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.2860 - accuracy: 0.9203 - val_loss: 0.1696 - val_accuracy: 0.9444\n",
      "Epoch 16/500\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.2216 - accuracy: 0.9177 - val_loss: 0.2409 - val_accuracy: 0.9402\n",
      "Epoch 17/500\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.3505 - accuracy: 0.9200 - val_loss: 0.1909 - val_accuracy: 0.9436\n",
      "Epoch 18/500\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.2351 - accuracy: 0.9160 - val_loss: 0.3159 - val_accuracy: 0.9462\n",
      "Epoch 19/500\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.2681 - accuracy: 0.9294 - val_loss: 0.2661 - val_accuracy: 0.9427\n",
      "Epoch 20/500\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.2241 - accuracy: 0.9149 - val_loss: 0.5861 - val_accuracy: 0.9342\n"
     ]
    }
   ],
   "source": [
    "# Fit the model: \n",
    "# Started 12:48 pm; ended pm --> 9 min to train \n",
    "fitted_inceptionV3_mod = fit_model(inceptionV3_mod, train_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 2s 37ms/step - loss: 0.6130 - accuracy: 0.9216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6129802465438843, 0.9216354489326477]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_inceptionV3_mod.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build model \n",
    "def build_resnet50V2_model(drop_rate):\n",
    "    \n",
    "    # Define input shape for the model \n",
    "    inputs = keras.Input(shape = (180, 180, 3))\n",
    "    # Resnet 50 basemodel \n",
    "    base_model = ResNet50V2(input_shape = (180, 180, 3), weights = 'imagenet', include_top = False)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = keras.applications.resnet_v2.preprocess_input(inputs)\n",
    "    x = base_model(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    " \n",
    "    x = keras.layers.Dense(256, activation = 'relu')(x)\n",
    "    x = keras.layers.Dropout(drop_rate)(x)\n",
    "    outputs = keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model: \n",
    "resnet50V2_mod = build_resnet50V2_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 62ms/step - loss: 1.9958 - accuracy: 0.8944 - val_loss: 0.1643 - val_accuracy: 0.9265\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 0.2709 - accuracy: 0.9342 - val_loss: 0.1457 - val_accuracy: 0.9556\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.2631 - accuracy: 0.9513 - val_loss: 0.1783 - val_accuracy: 0.9504\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1821 - accuracy: 0.9638 - val_loss: 0.1727 - val_accuracy: 0.9547\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0985 - accuracy: 0.9769 - val_loss: 0.1756 - val_accuracy: 0.9564\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0634 - accuracy: 0.9829 - val_loss: 0.7078 - val_accuracy: 0.9239\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 0.0768 - accuracy: 0.9826 - val_loss: 0.2488 - val_accuracy: 0.9624\n"
     ]
    }
   ],
   "source": [
    "# Fit the model: \n",
    "# Started 12:48 pm; ended pm --> 9 min to train \n",
    "resnet50V2_mod = fit_model(resnet50V2_mod, train_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 2s 39ms/step - loss: 0.5262 - accuracy: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5261532664299011, 0.9582623243331909]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50V2_mod.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://2f0b1158-0ad8-4ee0-8529-f38bd479d67f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://2f0b1158-0ad8-4ee0-8529-f38bd479d67f/assets\n"
     ]
    }
   ],
   "source": [
    "# maybe use docker instead of pickle\n",
    "\n",
    "import pickle\n",
    "filename = 'pneumonia_inceptionV.pkl'\n",
    "pickle.dump(fitted_inceptionV3_mod, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 63ms/step - loss: 4.6030 - accuracy: 0.9006 - val_loss: 0.3548 - val_accuracy: 0.9051\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.2245 - accuracy: 0.9584 - val_loss: 0.1035 - val_accuracy: 0.9632\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.1569 - accuracy: 0.9681 - val_loss: 0.0959 - val_accuracy: 0.9615\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.1098 - accuracy: 0.9761 - val_loss: 0.1350 - val_accuracy: 0.9675\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0695 - accuracy: 0.9860 - val_loss: 0.1340 - val_accuracy: 0.9632\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0481 - accuracy: 0.9880 - val_loss: 0.2449 - val_accuracy: 0.9308\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0397 - accuracy: 0.9892 - val_loss: 0.1686 - val_accuracy: 0.9658\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0331 - accuracy: 0.9909 - val_loss: 0.1932 - val_accuracy: 0.9650\n",
      "37/37 [==============================] - 2s 39ms/step - loss: 0.1846 - accuracy: 0.9710\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 56ms/step - loss: 42.1232 - accuracy: 0.8115 - val_loss: 0.4538 - val_accuracy: 0.8197\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 2.3060 - accuracy: 0.8004 - val_loss: 3.4448 - val_accuracy: 0.8658\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 1.1685 - accuracy: 0.8517 - val_loss: 0.2346 - val_accuracy: 0.9333\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.6196 - accuracy: 0.8642 - val_loss: 0.2481 - val_accuracy: 0.9128\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.6367 - accuracy: 0.8704 - val_loss: 0.2760 - val_accuracy: 0.9350\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3754 - accuracy: 0.8884 - val_loss: 0.1751 - val_accuracy: 0.9427\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3681 - accuracy: 0.8875 - val_loss: 0.1818 - val_accuracy: 0.9453\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3296 - accuracy: 0.8964 - val_loss: 0.1765 - val_accuracy: 0.9419\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3336 - accuracy: 0.8952 - val_loss: 0.3866 - val_accuracy: 0.9282\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2763 - accuracy: 0.8924 - val_loss: 0.2143 - val_accuracy: 0.9342\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3026 - accuracy: 0.9026 - val_loss: 0.2871 - val_accuracy: 0.9325\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.3015 - accuracy: 0.9191\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 64ms/step - loss: 5.4461 - accuracy: 0.9006 - val_loss: 0.2181 - val_accuracy: 0.9615\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.3586 - accuracy: 0.9559 - val_loss: 0.5985 - val_accuracy: 0.8692\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.1554 - accuracy: 0.9673 - val_loss: 0.1489 - val_accuracy: 0.9667\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1684 - accuracy: 0.9721 - val_loss: 0.1500 - val_accuracy: 0.9684\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1541 - accuracy: 0.9792 - val_loss: 0.3086 - val_accuracy: 0.9658\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0840 - accuracy: 0.9863 - val_loss: 0.2134 - val_accuracy: 0.9701\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0508 - accuracy: 0.9897 - val_loss: 0.5395 - val_accuracy: 0.9556\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0326 - accuracy: 0.9917 - val_loss: 0.2826 - val_accuracy: 0.9573\n",
      "37/37 [==============================] - 2s 39ms/step - loss: 0.3768 - accuracy: 0.9608\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 4.5340 - accuracy: 0.9021 - val_loss: 0.1238 - val_accuracy: 0.9641\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.2155 - accuracy: 0.9539 - val_loss: 0.1234 - val_accuracy: 0.9538\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1081 - accuracy: 0.9704 - val_loss: 0.1474 - val_accuracy: 0.9675\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0885 - accuracy: 0.9795 - val_loss: 0.0788 - val_accuracy: 0.9684\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0545 - accuracy: 0.9835 - val_loss: 0.1441 - val_accuracy: 0.9650\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0300 - accuracy: 0.9897 - val_loss: 0.2824 - val_accuracy: 0.9521\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0460 - accuracy: 0.9872 - val_loss: 0.2244 - val_accuracy: 0.9590\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.2047 - val_accuracy: 0.9624\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.1726 - val_accuracy: 0.9718\n",
      "37/37 [==============================] - 2s 39ms/step - loss: 0.2435 - accuracy: 0.9651\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 43.6557 - accuracy: 0.8050 - val_loss: 0.8346 - val_accuracy: 0.9034\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 1.6582 - accuracy: 0.8050 - val_loss: 0.2739 - val_accuracy: 0.9077\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 1.1020 - accuracy: 0.8331 - val_loss: 1.5886 - val_accuracy: 0.8573\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 1.1090 - accuracy: 0.8386 - val_loss: 0.2961 - val_accuracy: 0.9162\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9364 - accuracy: 0.8579 - val_loss: 0.2178 - val_accuracy: 0.9308\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.4137 - accuracy: 0.8630 - val_loss: 0.2618 - val_accuracy: 0.9299\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.6923 - accuracy: 0.8690 - val_loss: 0.2748 - val_accuracy: 0.9316\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6714 - accuracy: 0.8702 - val_loss: 0.2070 - val_accuracy: 0.9402\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3083 - accuracy: 0.8776 - val_loss: 0.2202 - val_accuracy: 0.9316\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5707 - accuracy: 0.8784 - val_loss: 0.1805 - val_accuracy: 0.9436\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3224 - accuracy: 0.8989 - val_loss: 0.2608 - val_accuracy: 0.9376\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3395 - accuracy: 0.9026 - val_loss: 0.2326 - val_accuracy: 0.9342\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3396 - accuracy: 0.9043 - val_loss: 0.1915 - val_accuracy: 0.9479\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2977 - accuracy: 0.9080 - val_loss: 0.2990 - val_accuracy: 0.9462\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2330 - accuracy: 0.9137 - val_loss: 0.2180 - val_accuracy: 0.9342\n",
      "37/37 [==============================] - 1s 33ms/step - loss: 0.2129 - accuracy: 0.9165\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 64ms/step - loss: 3.5963 - accuracy: 0.9021 - val_loss: 0.1833 - val_accuracy: 0.9547\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.2492 - accuracy: 0.9519 - val_loss: 0.1131 - val_accuracy: 0.9641\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.2079 - accuracy: 0.9621 - val_loss: 0.0977 - val_accuracy: 0.9624\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1011 - accuracy: 0.9758 - val_loss: 0.1197 - val_accuracy: 0.9692\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0702 - accuracy: 0.9843 - val_loss: 0.2892 - val_accuracy: 0.9521\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0457 - accuracy: 0.9872 - val_loss: 0.1593 - val_accuracy: 0.9556\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0481 - accuracy: 0.9883 - val_loss: 0.1681 - val_accuracy: 0.9684\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0358 - accuracy: 0.9917 - val_loss: 0.2470 - val_accuracy: 0.9658\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2556 - accuracy: 0.9676\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 5.7880 - accuracy: 0.9103 - val_loss: 1.7182 - val_accuracy: 0.9051\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3956 - accuracy: 0.9556 - val_loss: 0.1674 - val_accuracy: 0.9573\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2213 - accuracy: 0.9627 - val_loss: 0.1874 - val_accuracy: 0.9547\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1486 - accuracy: 0.9718 - val_loss: 0.5169 - val_accuracy: 0.9342\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1135 - accuracy: 0.9812 - val_loss: 0.6420 - val_accuracy: 0.9350\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1324 - accuracy: 0.9792 - val_loss: 0.2829 - val_accuracy: 0.9641\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1096 - accuracy: 0.9889 - val_loss: 0.5142 - val_accuracy: 0.9573\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.5474 - accuracy: 0.9532\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 38.0213 - accuracy: 0.8121 - val_loss: 0.3663 - val_accuracy: 0.9154\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.5202 - accuracy: 0.8383 - val_loss: 0.2480 - val_accuracy: 0.9239\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.8082 - accuracy: 0.8576 - val_loss: 0.2451 - val_accuracy: 0.9342\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.8117 - accuracy: 0.8733 - val_loss: 0.3030 - val_accuracy: 0.9308\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9148 - accuracy: 0.8776 - val_loss: 3.5601 - val_accuracy: 0.8521\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5829 - accuracy: 0.8756 - val_loss: 0.3796 - val_accuracy: 0.8915\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4526 - accuracy: 0.8838 - val_loss: 0.6516 - val_accuracy: 0.8538\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4529 - accuracy: 0.8969 - val_loss: 0.3524 - val_accuracy: 0.8983\n",
      "37/37 [==============================] - 1s 31ms/step - loss: 0.3827 - accuracy: 0.8935\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 4.4389 - accuracy: 0.9095 - val_loss: 0.1810 - val_accuracy: 0.9188\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2911 - accuracy: 0.9459 - val_loss: 0.3290 - val_accuracy: 0.9333\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1551 - accuracy: 0.9664 - val_loss: 0.1413 - val_accuracy: 0.9684\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1025 - accuracy: 0.9747 - val_loss: 0.1391 - val_accuracy: 0.9701\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1256 - accuracy: 0.9775 - val_loss: 0.1363 - val_accuracy: 0.9709\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0526 - accuracy: 0.9875 - val_loss: 0.1156 - val_accuracy: 0.9726\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0622 - accuracy: 0.9880 - val_loss: 0.5914 - val_accuracy: 0.9359\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.1619 - val_accuracy: 0.9684\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 0.2086 - val_accuracy: 0.9692\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0256 - accuracy: 0.9935 - val_loss: 0.1960 - val_accuracy: 0.9718\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0385 - accuracy: 0.9929 - val_loss: 0.2569 - val_accuracy: 0.9615\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3517 - accuracy: 0.9591\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 7.8896 - accuracy: 0.8972 - val_loss: 4.1868 - val_accuracy: 0.8462\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.7033 - accuracy: 0.9567 - val_loss: 0.2382 - val_accuracy: 0.9547\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2287 - accuracy: 0.9653 - val_loss: 0.1984 - val_accuracy: 0.9675\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1941 - accuracy: 0.9741 - val_loss: 0.5730 - val_accuracy: 0.9231\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1179 - accuracy: 0.9795 - val_loss: 0.2534 - val_accuracy: 0.9564\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1556 - accuracy: 0.9818 - val_loss: 0.2089 - val_accuracy: 0.9564\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0912 - accuracy: 0.9866 - val_loss: 0.2382 - val_accuracy: 0.9684\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0475 - accuracy: 0.9923 - val_loss: 0.3506 - val_accuracy: 0.9718\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3534 - accuracy: 0.9668\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 54ms/step - loss: 41.0026 - accuracy: 0.7961 - val_loss: 1.4936 - val_accuracy: 0.8564\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.4184 - accuracy: 0.8126 - val_loss: 0.3379 - val_accuracy: 0.9103\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.3222 - accuracy: 0.8485 - val_loss: 0.2902 - val_accuracy: 0.9068\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7632 - accuracy: 0.8528 - val_loss: 0.2282 - val_accuracy: 0.9316\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7480 - accuracy: 0.8798 - val_loss: 0.2342 - val_accuracy: 0.9376\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4279 - accuracy: 0.8858 - val_loss: 0.2351 - val_accuracy: 0.9368\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6538 - accuracy: 0.8949 - val_loss: 0.1924 - val_accuracy: 0.9239\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4632 - accuracy: 0.9006 - val_loss: 0.1871 - val_accuracy: 0.9453\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3139 - accuracy: 0.8995 - val_loss: 0.2129 - val_accuracy: 0.9350\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2697 - accuracy: 0.9046 - val_loss: 0.1811 - val_accuracy: 0.9316\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3475 - accuracy: 0.9046 - val_loss: 0.2917 - val_accuracy: 0.9214\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2787 - accuracy: 0.9089 - val_loss: 0.3533 - val_accuracy: 0.9068\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2606 - accuracy: 0.9026 - val_loss: 0.2759 - val_accuracy: 0.9436\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.2295 - accuracy: 0.9157 - val_loss: 0.2809 - val_accuracy: 0.9120\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2244 - accuracy: 0.9086 - val_loss: 0.2109 - val_accuracy: 0.9479\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.2271 - accuracy: 0.9327\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 63ms/step - loss: 5.0392 - accuracy: 0.9072 - val_loss: 2.7050 - val_accuracy: 0.8855\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4552 - accuracy: 0.9570 - val_loss: 0.1286 - val_accuracy: 0.9701\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1868 - accuracy: 0.9695 - val_loss: 0.1457 - val_accuracy: 0.9684\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1333 - accuracy: 0.9761 - val_loss: 0.1613 - val_accuracy: 0.9735\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1139 - accuracy: 0.9821 - val_loss: 0.2388 - val_accuracy: 0.9667\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0843 - accuracy: 0.9869 - val_loss: 0.3162 - val_accuracy: 0.9632\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0515 - accuracy: 0.9892 - val_loss: 0.1827 - val_accuracy: 0.9726\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2350 - accuracy: 0.9651\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 64ms/step - loss: 4.3847 - accuracy: 0.8972 - val_loss: 0.1069 - val_accuracy: 0.9615\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1345 - accuracy: 0.9618 - val_loss: 1.3815 - val_accuracy: 0.7470\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1363 - accuracy: 0.9647 - val_loss: 0.1109 - val_accuracy: 0.9684\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0768 - accuracy: 0.9758 - val_loss: 0.1554 - val_accuracy: 0.9718\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0801 - accuracy: 0.9772 - val_loss: 0.1067 - val_accuracy: 0.9752\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0411 - accuracy: 0.9872 - val_loss: 0.2691 - val_accuracy: 0.9598\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0309 - accuracy: 0.9906 - val_loss: 0.1590 - val_accuracy: 0.9701\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0218 - accuracy: 0.9935 - val_loss: 0.2052 - val_accuracy: 0.9667\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0492 - accuracy: 0.9895 - val_loss: 0.2172 - val_accuracy: 0.9598\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0316 - accuracy: 0.9923 - val_loss: 0.2164 - val_accuracy: 0.9624\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2171 - accuracy: 0.9659\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 54ms/step - loss: 39.6179 - accuracy: 0.8166 - val_loss: 0.4736 - val_accuracy: 0.8829\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.2360 - accuracy: 0.8092 - val_loss: 0.7312 - val_accuracy: 0.8632\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.8449 - accuracy: 0.8317 - val_loss: 0.2533 - val_accuracy: 0.9162\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9077 - accuracy: 0.8630 - val_loss: 0.3571 - val_accuracy: 0.9231\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5788 - accuracy: 0.8707 - val_loss: 0.4388 - val_accuracy: 0.9222\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6373 - accuracy: 0.8818 - val_loss: 0.2066 - val_accuracy: 0.9427\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4757 - accuracy: 0.8818 - val_loss: 0.3609 - val_accuracy: 0.9009\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3606 - accuracy: 0.8847 - val_loss: 0.2394 - val_accuracy: 0.9462\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4090 - accuracy: 0.8935 - val_loss: 0.6476 - val_accuracy: 0.9393\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3213 - accuracy: 0.8938 - val_loss: 0.3255 - val_accuracy: 0.9419\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3585 - accuracy: 0.8995 - val_loss: 0.1894 - val_accuracy: 0.9513\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2556 - accuracy: 0.8981 - val_loss: 0.2143 - val_accuracy: 0.9299\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2892 - accuracy: 0.9120 - val_loss: 0.2064 - val_accuracy: 0.9239\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3070 - accuracy: 0.9151 - val_loss: 0.2946 - val_accuracy: 0.9350\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2724 - accuracy: 0.9083 - val_loss: 0.1906 - val_accuracy: 0.9496\n",
      "Epoch 16/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2210 - accuracy: 0.9203 - val_loss: 0.2084 - val_accuracy: 0.9282\n",
      "37/37 [==============================] - 1s 31ms/step - loss: 0.2118 - accuracy: 0.9208\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 63ms/step - loss: 4.4834 - accuracy: 0.9046 - val_loss: 0.6450 - val_accuracy: 0.9590\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3656 - accuracy: 0.9530 - val_loss: 0.1571 - val_accuracy: 0.9504\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.2737 - accuracy: 0.9587 - val_loss: 0.2781 - val_accuracy: 0.9205\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1535 - accuracy: 0.9727 - val_loss: 0.2723 - val_accuracy: 0.9581\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2179 - accuracy: 0.9729 - val_loss: 0.2216 - val_accuracy: 0.9624\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0911 - accuracy: 0.9821 - val_loss: 0.2531 - val_accuracy: 0.9658\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1378 - accuracy: 0.9804 - val_loss: 0.2817 - val_accuracy: 0.9744\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3323 - accuracy: 0.9668\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 6.0672 - accuracy: 0.9086 - val_loss: 1.2937 - val_accuracy: 0.9504\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5782 - accuracy: 0.9567 - val_loss: 0.1858 - val_accuracy: 0.9692\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1986 - accuracy: 0.9630 - val_loss: 0.1674 - val_accuracy: 0.9590\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.3690 - accuracy: 0.9675 - val_loss: 0.1360 - val_accuracy: 0.9752\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1887 - accuracy: 0.9761 - val_loss: 0.3662 - val_accuracy: 0.9701\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0880 - accuracy: 0.9869 - val_loss: 0.3140 - val_accuracy: 0.9564\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1389 - accuracy: 0.9798 - val_loss: 0.3018 - val_accuracy: 0.9453\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0807 - accuracy: 0.9858 - val_loss: 0.3180 - val_accuracy: 0.9607\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0511 - accuracy: 0.9917 - val_loss: 0.3253 - val_accuracy: 0.9726\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3375 - accuracy: 0.9710\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 41.7485 - accuracy: 0.8206 - val_loss: 0.3739 - val_accuracy: 0.8231\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.4495 - accuracy: 0.8425 - val_loss: 0.8601 - val_accuracy: 0.9179\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.0595 - accuracy: 0.8591 - val_loss: 13.1765 - val_accuracy: 0.6479\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7010 - accuracy: 0.8818 - val_loss: 0.3589 - val_accuracy: 0.8949\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9041 - accuracy: 0.8716 - val_loss: 0.2889 - val_accuracy: 0.9231\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6538 - accuracy: 0.8890 - val_loss: 0.2171 - val_accuracy: 0.9462\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5898 - accuracy: 0.8998 - val_loss: 0.2533 - val_accuracy: 0.9419\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3177 - accuracy: 0.9077 - val_loss: 0.2338 - val_accuracy: 0.9453\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3456 - accuracy: 0.9080 - val_loss: 0.3002 - val_accuracy: 0.9436\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6046 - accuracy: 0.9143 - val_loss: 0.2193 - val_accuracy: 0.9470\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3134 - accuracy: 0.9103 - val_loss: 1.0173 - val_accuracy: 0.8675\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 1.0276 - accuracy: 0.8714\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 63ms/step - loss: 5.7989 - accuracy: 0.9009 - val_loss: 1.5277 - val_accuracy: 0.7932\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.2598 - accuracy: 0.9507 - val_loss: 0.1367 - val_accuracy: 0.9521\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1991 - accuracy: 0.9621 - val_loss: 0.1781 - val_accuracy: 0.9496\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1165 - accuracy: 0.9752 - val_loss: 0.1939 - val_accuracy: 0.9607\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1298 - accuracy: 0.9792 - val_loss: 0.2105 - val_accuracy: 0.9667\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0711 - accuracy: 0.9812 - val_loss: 0.1591 - val_accuracy: 0.9709\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1020 - accuracy: 0.9849 - val_loss: 0.1582 - val_accuracy: 0.9701\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2284 - accuracy: 0.9702\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 6.3265 - accuracy: 0.9086 - val_loss: 0.7003 - val_accuracy: 0.9590\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4685 - accuracy: 0.9499 - val_loss: 0.1522 - val_accuracy: 0.9675\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.4455 - accuracy: 0.9522 - val_loss: 1.6247 - val_accuracy: 0.8564\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1302 - accuracy: 0.9744 - val_loss: 0.2544 - val_accuracy: 0.9692\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1468 - accuracy: 0.9764 - val_loss: 0.5107 - val_accuracy: 0.9564\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2250 - accuracy: 0.9778 - val_loss: 0.3619 - val_accuracy: 0.9615\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0791 - accuracy: 0.9889 - val_loss: 0.2493 - val_accuracy: 0.9590\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3433 - accuracy: 0.9600\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 31.0966 - accuracy: 0.7896 - val_loss: 0.4547 - val_accuracy: 0.8496\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.5361 - accuracy: 0.8388 - val_loss: 0.4092 - val_accuracy: 0.9308\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7373 - accuracy: 0.8545 - val_loss: 0.3048 - val_accuracy: 0.9325\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9361 - accuracy: 0.8736 - val_loss: 0.2785 - val_accuracy: 0.9350\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5306 - accuracy: 0.8835 - val_loss: 0.2297 - val_accuracy: 0.9453\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9571 - accuracy: 0.8887 - val_loss: 0.3445 - val_accuracy: 0.9453\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7468 - accuracy: 0.8898 - val_loss: 0.2059 - val_accuracy: 0.9444\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3439 - accuracy: 0.8915 - val_loss: 0.2728 - val_accuracy: 0.9291\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3566 - accuracy: 0.8964 - val_loss: 0.1671 - val_accuracy: 0.9427\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3190 - accuracy: 0.9055 - val_loss: 0.1947 - val_accuracy: 0.9393\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3542 - accuracy: 0.9075 - val_loss: 0.3170 - val_accuracy: 0.9402\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4498 - accuracy: 0.9003 - val_loss: 0.2434 - val_accuracy: 0.9385\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2780 - accuracy: 0.9154 - val_loss: 0.3059 - val_accuracy: 0.9393\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2646 - accuracy: 0.9060 - val_loss: 0.1961 - val_accuracy: 0.9325\n",
      "37/37 [==============================] - 1s 31ms/step - loss: 0.2164 - accuracy: 0.9157\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 5.9907 - accuracy: 0.9075 - val_loss: 1.2716 - val_accuracy: 0.9256\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.6642 - accuracy: 0.9499 - val_loss: 0.5895 - val_accuracy: 0.9479\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2716 - accuracy: 0.9604 - val_loss: 0.4159 - val_accuracy: 0.9504\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2127 - accuracy: 0.9690 - val_loss: 0.1127 - val_accuracy: 0.9718\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1325 - accuracy: 0.9778 - val_loss: 0.1517 - val_accuracy: 0.9709\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1111 - accuracy: 0.9806 - val_loss: 0.2107 - val_accuracy: 0.9581\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0639 - accuracy: 0.9855 - val_loss: 0.2461 - val_accuracy: 0.9667\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1509 - accuracy: 0.9841 - val_loss: 0.4432 - val_accuracy: 0.9632\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0257 - accuracy: 0.9946 - val_loss: 0.3851 - val_accuracy: 0.9667\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.4452 - accuracy: 0.9668\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 7.0570 - accuracy: 0.9026 - val_loss: 0.4996 - val_accuracy: 0.9658\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.7492 - accuracy: 0.9479 - val_loss: 0.3431 - val_accuracy: 0.9564\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4354 - accuracy: 0.9613 - val_loss: 0.2404 - val_accuracy: 0.9590\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3704 - accuracy: 0.9710 - val_loss: 0.6751 - val_accuracy: 0.9359\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2576 - accuracy: 0.9735 - val_loss: 0.2757 - val_accuracy: 0.9667\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2076 - accuracy: 0.9747 - val_loss: 0.2510 - val_accuracy: 0.9658\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1360 - accuracy: 0.9858 - val_loss: 0.6106 - val_accuracy: 0.9402\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0831 - accuracy: 0.9886 - val_loss: 0.4506 - val_accuracy: 0.9658\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.4990 - accuracy: 0.9668\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 46.5189 - accuracy: 0.8249 - val_loss: 0.4965 - val_accuracy: 0.9179\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.8857 - accuracy: 0.8013 - val_loss: 0.3700 - val_accuracy: 0.9248\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.8137 - accuracy: 0.8397 - val_loss: 0.3595 - val_accuracy: 0.8855\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.1302 - accuracy: 0.8368 - val_loss: 0.5483 - val_accuracy: 0.9120\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5407 - accuracy: 0.8736 - val_loss: 0.3667 - val_accuracy: 0.8957\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6903 - accuracy: 0.8793 - val_loss: 0.2701 - val_accuracy: 0.9256\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3968 - accuracy: 0.8855 - val_loss: 0.2395 - val_accuracy: 0.9342\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5882 - accuracy: 0.8927 - val_loss: 0.2331 - val_accuracy: 0.9427\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4123 - accuracy: 0.8904 - val_loss: 0.3718 - val_accuracy: 0.9427\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2750 - accuracy: 0.9006 - val_loss: 0.3638 - val_accuracy: 0.9342\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4595 - accuracy: 0.8983 - val_loss: 0.3115 - val_accuracy: 0.9171\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2951 - accuracy: 0.9063 - val_loss: 0.9578 - val_accuracy: 0.8393\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5162 - accuracy: 0.9029 - val_loss: 0.2253 - val_accuracy: 0.9385\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2891 - accuracy: 0.9160 - val_loss: 0.3347 - val_accuracy: 0.9453\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2716 - accuracy: 0.9174 - val_loss: 0.2232 - val_accuracy: 0.9299\n",
      "Epoch 16/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2179 - accuracy: 0.9169 - val_loss: 0.2703 - val_accuracy: 0.9402\n",
      "Epoch 17/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2519 - accuracy: 0.9180 - val_loss: 0.2387 - val_accuracy: 0.9325\n",
      "Epoch 18/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2497 - accuracy: 0.9174 - val_loss: 0.2652 - val_accuracy: 0.9402\n",
      "Epoch 19/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.1999 - accuracy: 0.9077 - val_loss: 0.3079 - val_accuracy: 0.9444\n",
      "Epoch 20/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2741 - accuracy: 0.9171 - val_loss: 0.2792 - val_accuracy: 0.9402\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.3615 - accuracy: 0.9174\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 63ms/step - loss: 7.0642 - accuracy: 0.9069 - val_loss: 0.4973 - val_accuracy: 0.9342\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4100 - accuracy: 0.9487 - val_loss: 0.2667 - val_accuracy: 0.9692\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3105 - accuracy: 0.9553 - val_loss: 0.1083 - val_accuracy: 0.9658\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2302 - accuracy: 0.9687 - val_loss: 0.7585 - val_accuracy: 0.8915\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1943 - accuracy: 0.9755 - val_loss: 0.2022 - val_accuracy: 0.9641\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1439 - accuracy: 0.9809 - val_loss: 0.1799 - val_accuracy: 0.9684\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0875 - accuracy: 0.9886 - val_loss: 0.7448 - val_accuracy: 0.9444\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1275 - accuracy: 0.9841 - val_loss: 0.3703 - val_accuracy: 0.9632\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.4457 - accuracy: 0.9651\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 63ms/step - loss: 6.7911 - accuracy: 0.9055 - val_loss: 0.2422 - val_accuracy: 0.9607\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4440 - accuracy: 0.9431 - val_loss: 0.1551 - val_accuracy: 0.9607\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2198 - accuracy: 0.9604 - val_loss: 0.2125 - val_accuracy: 0.9641\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1588 - accuracy: 0.9692 - val_loss: 0.1368 - val_accuracy: 0.9632\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1287 - accuracy: 0.9721 - val_loss: 0.3779 - val_accuracy: 0.9470\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0965 - accuracy: 0.9826 - val_loss: 0.1387 - val_accuracy: 0.9658\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0744 - accuracy: 0.9846 - val_loss: 0.2440 - val_accuracy: 0.9658\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0572 - accuracy: 0.9880 - val_loss: 0.1842 - val_accuracy: 0.9667\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0442 - accuracy: 0.9937 - val_loss: 0.2655 - val_accuracy: 0.9726\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3209 - accuracy: 0.9676\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 54ms/step - loss: 42.6977 - accuracy: 0.8243 - val_loss: 0.4830 - val_accuracy: 0.9051\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.4588 - accuracy: 0.8363 - val_loss: 0.7783 - val_accuracy: 0.9085\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9397 - accuracy: 0.8568 - val_loss: 0.3164 - val_accuracy: 0.9017\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7375 - accuracy: 0.8727 - val_loss: 0.2713 - val_accuracy: 0.9222\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6942 - accuracy: 0.8847 - val_loss: 1.7608 - val_accuracy: 0.8838\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4964 - accuracy: 0.8798 - val_loss: 0.2785 - val_accuracy: 0.9444\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5259 - accuracy: 0.8972 - val_loss: 2.6095 - val_accuracy: 0.7513\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4015 - accuracy: 0.8892 - val_loss: 0.2138 - val_accuracy: 0.9419\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3075 - accuracy: 0.8932 - val_loss: 0.1935 - val_accuracy: 0.9419\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3585 - accuracy: 0.8955 - val_loss: 0.3678 - val_accuracy: 0.9419\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3058 - accuracy: 0.9046 - val_loss: 0.1879 - val_accuracy: 0.9385\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2585 - accuracy: 0.9114 - val_loss: 0.2384 - val_accuracy: 0.9402\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2214 - accuracy: 0.9058 - val_loss: 0.2229 - val_accuracy: 0.9419\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2553 - accuracy: 0.9140 - val_loss: 0.2357 - val_accuracy: 0.9453\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2649 - accuracy: 0.9274 - val_loss: 0.2046 - val_accuracy: 0.9427\n",
      "Epoch 16/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.1896 - accuracy: 0.9231 - val_loss: 0.3565 - val_accuracy: 0.9487\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.4080 - accuracy: 0.9293\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 3.1726 - accuracy: 0.9018 - val_loss: 0.1630 - val_accuracy: 0.9598\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2084 - accuracy: 0.9496 - val_loss: 0.1339 - val_accuracy: 0.9590\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1692 - accuracy: 0.9650 - val_loss: 0.1405 - val_accuracy: 0.9624\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0963 - accuracy: 0.9735 - val_loss: 0.2037 - val_accuracy: 0.9556\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1223 - accuracy: 0.9732 - val_loss: 0.1090 - val_accuracy: 0.9632\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0738 - accuracy: 0.9832 - val_loss: 0.1096 - val_accuracy: 0.9709\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0970 - accuracy: 0.9835 - val_loss: 0.1267 - val_accuracy: 0.9675\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0504 - accuracy: 0.9909 - val_loss: 0.1839 - val_accuracy: 0.9624\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0487 - accuracy: 0.9866 - val_loss: 0.1562 - val_accuracy: 0.9641\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.1882 - val_accuracy: 0.9684\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2432 - accuracy: 0.9651\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 8.6848 - accuracy: 0.9052 - val_loss: 0.6581 - val_accuracy: 0.9675\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.8966 - accuracy: 0.9482 - val_loss: 0.3253 - val_accuracy: 0.9556\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2886 - accuracy: 0.9641 - val_loss: 0.5610 - val_accuracy: 0.9402\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3810 - accuracy: 0.9650 - val_loss: 0.4674 - val_accuracy: 0.9521\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.3488 - accuracy: 0.9687 - val_loss: 0.4826 - val_accuracy: 0.9581\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1256 - accuracy: 0.9835 - val_loss: 0.2643 - val_accuracy: 0.9761\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1324 - accuracy: 0.9832 - val_loss: 0.2696 - val_accuracy: 0.9735\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0980 - accuracy: 0.9846 - val_loss: 0.4054 - val_accuracy: 0.9598\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1110 - accuracy: 0.9875 - val_loss: 0.4250 - val_accuracy: 0.9650\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0569 - accuracy: 0.9912 - val_loss: 0.4231 - val_accuracy: 0.9726\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0819 - accuracy: 0.9926 - val_loss: 0.5587 - val_accuracy: 0.9701\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.7093 - accuracy: 0.9668\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 56ms/step - loss: 47.6612 - accuracy: 0.8098 - val_loss: 0.6314 - val_accuracy: 0.8803\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.4746 - accuracy: 0.8252 - val_loss: 0.3739 - val_accuracy: 0.9094\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.6038 - accuracy: 0.8545 - val_loss: 0.2783 - val_accuracy: 0.9205\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5957 - accuracy: 0.8647 - val_loss: 0.2636 - val_accuracy: 0.9376\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5104 - accuracy: 0.8824 - val_loss: 0.3237 - val_accuracy: 0.9427\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9140 - accuracy: 0.8801 - val_loss: 0.2616 - val_accuracy: 0.9308\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3161 - accuracy: 0.8944 - val_loss: 0.3463 - val_accuracy: 0.9291\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6183 - accuracy: 0.8830 - val_loss: 0.2347 - val_accuracy: 0.9427\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3143 - accuracy: 0.8983 - val_loss: 0.2614 - val_accuracy: 0.9043\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3989 - accuracy: 0.9035 - val_loss: 0.2727 - val_accuracy: 0.9444\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2691 - accuracy: 0.9055 - val_loss: 0.2542 - val_accuracy: 0.9342\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3510 - accuracy: 0.9029 - val_loss: 0.2087 - val_accuracy: 0.9282\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2810 - accuracy: 0.9080 - val_loss: 0.3537 - val_accuracy: 0.9402\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2573 - accuracy: 0.9126 - val_loss: 0.2136 - val_accuracy: 0.9419\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2725 - accuracy: 0.9160 - val_loss: 0.2464 - val_accuracy: 0.9470\n",
      "Epoch 16/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2298 - accuracy: 0.9151 - val_loss: 0.3610 - val_accuracy: 0.9368\n",
      "Epoch 17/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3291 - accuracy: 0.9143 - val_loss: 0.2809 - val_accuracy: 0.9325\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.3529 - accuracy: 0.9131\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 64ms/step - loss: 4.9162 - accuracy: 0.9038 - val_loss: 0.1702 - val_accuracy: 0.9385\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3652 - accuracy: 0.9433 - val_loss: 0.2793 - val_accuracy: 0.9308\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1865 - accuracy: 0.9533 - val_loss: 0.2643 - val_accuracy: 0.9538\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1317 - accuracy: 0.9715 - val_loss: 0.1453 - val_accuracy: 0.9744\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1299 - accuracy: 0.9744 - val_loss: 0.1663 - val_accuracy: 0.9632\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1404 - accuracy: 0.9747 - val_loss: 0.2199 - val_accuracy: 0.9667\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1174 - accuracy: 0.9818 - val_loss: 0.1840 - val_accuracy: 0.9684\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0483 - accuracy: 0.9878 - val_loss: 0.2371 - val_accuracy: 0.9624\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0541 - accuracy: 0.9883 - val_loss: 0.1537 - val_accuracy: 0.9650\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2371 - accuracy: 0.9693\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 4.4491 - accuracy: 0.8981 - val_loss: 0.1028 - val_accuracy: 0.9607\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2859 - accuracy: 0.9374 - val_loss: 0.1621 - val_accuracy: 0.9547\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2321 - accuracy: 0.9570 - val_loss: 0.1922 - val_accuracy: 0.9538\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1461 - accuracy: 0.9690 - val_loss: 0.2026 - val_accuracy: 0.9590\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0897 - accuracy: 0.9738 - val_loss: 0.1337 - val_accuracy: 0.9684\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0797 - accuracy: 0.9764 - val_loss: 0.2622 - val_accuracy: 0.9504\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3051 - accuracy: 0.9523\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 40.8574 - accuracy: 0.8252 - val_loss: 0.3786 - val_accuracy: 0.8863\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.2491 - accuracy: 0.8269 - val_loss: 0.2227 - val_accuracy: 0.9248\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.3233 - accuracy: 0.8559 - val_loss: 0.4747 - val_accuracy: 0.8863\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.1707 - accuracy: 0.8690 - val_loss: 0.3079 - val_accuracy: 0.9188\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6579 - accuracy: 0.8864 - val_loss: 0.4247 - val_accuracy: 0.9427\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.1473 - accuracy: 0.8921 - val_loss: 0.2242 - val_accuracy: 0.9342\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4875 - accuracy: 0.8952 - val_loss: 0.2185 - val_accuracy: 0.9410\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5049 - accuracy: 0.8995 - val_loss: 0.2150 - val_accuracy: 0.9368\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5089 - accuracy: 0.9023 - val_loss: 0.2698 - val_accuracy: 0.9436\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4403 - accuracy: 0.8972 - val_loss: 1.0773 - val_accuracy: 0.8718\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2833 - accuracy: 0.9120 - val_loss: 0.3357 - val_accuracy: 0.9521\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3711 - accuracy: 0.9015 - val_loss: 0.1907 - val_accuracy: 0.9436\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2837 - accuracy: 0.9095 - val_loss: 0.3314 - val_accuracy: 0.9385\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2536 - accuracy: 0.8989 - val_loss: 0.2061 - val_accuracy: 0.9385\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4730 - accuracy: 0.9203 - val_loss: 0.2778 - val_accuracy: 0.9487\n",
      "Epoch 16/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2454 - accuracy: 0.9200 - val_loss: 0.2482 - val_accuracy: 0.9453\n",
      "Epoch 17/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2037 - accuracy: 0.9251 - val_loss: 0.2471 - val_accuracy: 0.9470\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.2416 - accuracy: 0.9284\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 5.7977 - accuracy: 0.9120 - val_loss: 0.6883 - val_accuracy: 0.9632\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.6203 - accuracy: 0.9516 - val_loss: 0.7114 - val_accuracy: 0.9427\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.3706 - accuracy: 0.9590 - val_loss: 0.1653 - val_accuracy: 0.9521\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2732 - accuracy: 0.9707 - val_loss: 0.2952 - val_accuracy: 0.9402\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2667 - accuracy: 0.9758 - val_loss: 0.3533 - val_accuracy: 0.9667\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2292 - accuracy: 0.9761 - val_loss: 0.2032 - val_accuracy: 0.9684\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1654 - accuracy: 0.9789 - val_loss: 0.1993 - val_accuracy: 0.9701\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0961 - accuracy: 0.9875 - val_loss: 0.8176 - val_accuracy: 0.9581\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.9427 - accuracy: 0.9523\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 63ms/step - loss: 5.3260 - accuracy: 0.9035 - val_loss: 0.4884 - val_accuracy: 0.9137\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.3095 - accuracy: 0.9510 - val_loss: 0.1317 - val_accuracy: 0.9581\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2857 - accuracy: 0.9533 - val_loss: 0.1776 - val_accuracy: 0.9667\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1519 - accuracy: 0.9735 - val_loss: 0.2077 - val_accuracy: 0.9632\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1560 - accuracy: 0.9752 - val_loss: 0.1794 - val_accuracy: 0.9658\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0991 - accuracy: 0.9798 - val_loss: 0.1736 - val_accuracy: 0.9701\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1397 - accuracy: 0.9804 - val_loss: 0.2688 - val_accuracy: 0.9658\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3413 - accuracy: 0.9625\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 54ms/step - loss: 44.9399 - accuracy: 0.8334 - val_loss: 1.9194 - val_accuracy: 0.8120\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.0735 - accuracy: 0.8237 - val_loss: 2.0858 - val_accuracy: 0.8350\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.2089 - accuracy: 0.8596 - val_loss: 0.3357 - val_accuracy: 0.9154\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.3419 - accuracy: 0.8710 - val_loss: 0.2109 - val_accuracy: 0.9410\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5868 - accuracy: 0.8764 - val_loss: 0.3277 - val_accuracy: 0.9342\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3084 - accuracy: 0.8918 - val_loss: 0.2357 - val_accuracy: 0.9419\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4613 - accuracy: 0.8790 - val_loss: 1.1736 - val_accuracy: 0.9017\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6335 - accuracy: 0.8958 - val_loss: 0.5644 - val_accuracy: 0.9402\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4204 - accuracy: 0.8895 - val_loss: 0.2043 - val_accuracy: 0.9197\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3405 - accuracy: 0.8958 - val_loss: 0.2843 - val_accuracy: 0.9094\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3087 - accuracy: 0.9060 - val_loss: 0.2849 - val_accuracy: 0.9359\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3185 - accuracy: 0.9003 - val_loss: 0.2445 - val_accuracy: 0.9282\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2569 - accuracy: 0.9077 - val_loss: 0.2204 - val_accuracy: 0.9487\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4294 - accuracy: 0.9086 - val_loss: 0.2227 - val_accuracy: 0.9453\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.2593 - accuracy: 0.9319\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 2.4243 - accuracy: 0.9052 - val_loss: 0.1622 - val_accuracy: 0.9607\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.3252 - accuracy: 0.9411 - val_loss: 0.1981 - val_accuracy: 0.9368\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1790 - accuracy: 0.9599 - val_loss: 0.3158 - val_accuracy: 0.9615\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1449 - accuracy: 0.9661 - val_loss: 0.0886 - val_accuracy: 0.9701\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1051 - accuracy: 0.9755 - val_loss: 0.1105 - val_accuracy: 0.9709\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0850 - accuracy: 0.9801 - val_loss: 0.1385 - val_accuracy: 0.9744\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0729 - accuracy: 0.9806 - val_loss: 0.1134 - val_accuracy: 0.9692\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0467 - accuracy: 0.9852 - val_loss: 0.1524 - val_accuracy: 0.9718\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0604 - accuracy: 0.9866 - val_loss: 0.1654 - val_accuracy: 0.9692\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2085 - accuracy: 0.9685\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 64ms/step - loss: 3.8623 - accuracy: 0.9040 - val_loss: 0.1105 - val_accuracy: 0.9547\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2496 - accuracy: 0.9456 - val_loss: 0.3174 - val_accuracy: 0.9333\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2653 - accuracy: 0.9539 - val_loss: 0.1606 - val_accuracy: 0.9718\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1133 - accuracy: 0.9710 - val_loss: 0.3433 - val_accuracy: 0.9248\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1449 - accuracy: 0.9744 - val_loss: 0.1693 - val_accuracy: 0.9573\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0981 - accuracy: 0.9789 - val_loss: 0.1322 - val_accuracy: 0.9692\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.1733 - accuracy: 0.9668\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 35.5118 - accuracy: 0.8181 - val_loss: 0.5464 - val_accuracy: 0.8026\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.4041 - accuracy: 0.8200 - val_loss: 0.5772 - val_accuracy: 0.8812\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 1.3068 - accuracy: 0.8334 - val_loss: 0.3262 - val_accuracy: 0.8786\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.2624 - accuracy: 0.8337 - val_loss: 0.4147 - val_accuracy: 0.9103\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7841 - accuracy: 0.8534 - val_loss: 0.2465 - val_accuracy: 0.9359\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5425 - accuracy: 0.8613 - val_loss: 0.2977 - val_accuracy: 0.9410\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4055 - accuracy: 0.8835 - val_loss: 0.8620 - val_accuracy: 0.8265\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4527 - accuracy: 0.8924 - val_loss: 0.2744 - val_accuracy: 0.9385\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5860 - accuracy: 0.8904 - val_loss: 0.2637 - val_accuracy: 0.9333\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2986 - accuracy: 0.8978 - val_loss: 0.3020 - val_accuracy: 0.9402\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.3192 - accuracy: 0.9310\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 6.7434 - accuracy: 0.9052 - val_loss: 7.6004 - val_accuracy: 0.6889\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.6482 - accuracy: 0.9453 - val_loss: 0.1269 - val_accuracy: 0.9650\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2622 - accuracy: 0.9573 - val_loss: 0.1872 - val_accuracy: 0.9615\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2784 - accuracy: 0.9633 - val_loss: 0.2288 - val_accuracy: 0.9701\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2122 - accuracy: 0.9704 - val_loss: 0.1229 - val_accuracy: 0.9590\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0908 - accuracy: 0.9786 - val_loss: 0.6915 - val_accuracy: 0.9282\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1269 - accuracy: 0.9809 - val_loss: 0.3980 - val_accuracy: 0.9650\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1134 - accuracy: 0.9843 - val_loss: 0.5797 - val_accuracy: 0.9496\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1157 - accuracy: 0.9863 - val_loss: 0.2435 - val_accuracy: 0.9667\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0867 - accuracy: 0.9897 - val_loss: 0.4180 - val_accuracy: 0.9701\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.4985 - accuracy: 0.9685\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 4.6629 - accuracy: 0.9086 - val_loss: 0.4564 - val_accuracy: 0.9504\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4826 - accuracy: 0.9450 - val_loss: 0.2294 - val_accuracy: 0.9598\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2524 - accuracy: 0.9627 - val_loss: 0.1213 - val_accuracy: 0.9692\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3033 - accuracy: 0.9653 - val_loss: 0.3118 - val_accuracy: 0.9547\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1805 - accuracy: 0.9715 - val_loss: 0.2172 - val_accuracy: 0.9692\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1650 - accuracy: 0.9738 - val_loss: 0.8840 - val_accuracy: 0.9291\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1422 - accuracy: 0.9798 - val_loss: 0.3515 - val_accuracy: 0.9650\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1495 - accuracy: 0.9809 - val_loss: 0.5654 - val_accuracy: 0.9068\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.5522 - accuracy: 0.9233\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 54ms/step - loss: 30.7463 - accuracy: 0.8064 - val_loss: 0.5847 - val_accuracy: 0.8060\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.3270 - accuracy: 0.8115 - val_loss: 0.3011 - val_accuracy: 0.8709\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.2758 - accuracy: 0.8141 - val_loss: 0.3297 - val_accuracy: 0.9265\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.3820 - accuracy: 0.8252 - val_loss: 0.2002 - val_accuracy: 0.9385\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.1484 - accuracy: 0.8585 - val_loss: 0.3937 - val_accuracy: 0.9316\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6402 - accuracy: 0.8679 - val_loss: 0.7171 - val_accuracy: 0.9000\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5794 - accuracy: 0.8699 - val_loss: 4.4476 - val_accuracy: 0.8171\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5277 - accuracy: 0.8719 - val_loss: 0.2888 - val_accuracy: 0.9342\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4997 - accuracy: 0.8835 - val_loss: 0.2063 - val_accuracy: 0.9085\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.2522 - accuracy: 0.8756\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 64ms/step - loss: 3.8486 - accuracy: 0.9086 - val_loss: 0.4152 - val_accuracy: 0.9470\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.4163 - accuracy: 0.9479 - val_loss: 0.1963 - val_accuracy: 0.9479\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2934 - accuracy: 0.9553 - val_loss: 0.2037 - val_accuracy: 0.9726\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3117 - accuracy: 0.9610 - val_loss: 0.3427 - val_accuracy: 0.9556\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2045 - accuracy: 0.9695 - val_loss: 0.1767 - val_accuracy: 0.9598\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1292 - accuracy: 0.9786 - val_loss: 0.1986 - val_accuracy: 0.9650\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1195 - accuracy: 0.9801 - val_loss: 0.1988 - val_accuracy: 0.9667\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1010 - accuracy: 0.9835 - val_loss: 0.4281 - val_accuracy: 0.9521\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0998 - accuracy: 0.9843 - val_loss: 0.2275 - val_accuracy: 0.9761\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0715 - accuracy: 0.9886 - val_loss: 0.2627 - val_accuracy: 0.9692\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3069 - accuracy: 0.9702\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 4.6939 - accuracy: 0.9032 - val_loss: 0.2019 - val_accuracy: 0.9547\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2945 - accuracy: 0.9479 - val_loss: 0.1713 - val_accuracy: 0.9573\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1896 - accuracy: 0.9613 - val_loss: 0.2066 - val_accuracy: 0.9598\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2725 - accuracy: 0.9607 - val_loss: 0.1549 - val_accuracy: 0.9658\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1313 - accuracy: 0.9752 - val_loss: 1.1175 - val_accuracy: 0.8598\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1111 - accuracy: 0.9792 - val_loss: 0.2700 - val_accuracy: 0.9564\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1178 - accuracy: 0.9806 - val_loss: 0.2435 - val_accuracy: 0.9581\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0606 - accuracy: 0.9892 - val_loss: 0.1379 - val_accuracy: 0.9709\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0650 - accuracy: 0.9863 - val_loss: 0.1898 - val_accuracy: 0.9709\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0389 - accuracy: 0.9912 - val_loss: 0.2364 - val_accuracy: 0.9581\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0409 - accuracy: 0.9926 - val_loss: 0.3506 - val_accuracy: 0.9667\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0521 - accuracy: 0.9909 - val_loss: 0.1969 - val_accuracy: 0.9709\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0477 - accuracy: 0.9932 - val_loss: 0.3027 - val_accuracy: 0.9658\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3454 - accuracy: 0.9642\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 37.1645 - accuracy: 0.8158 - val_loss: 6.2964 - val_accuracy: 0.7393\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.9794 - accuracy: 0.8294 - val_loss: 6.1225 - val_accuracy: 0.6231\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.2257 - accuracy: 0.8554 - val_loss: 1.0112 - val_accuracy: 0.8795\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.9607 - accuracy: 0.8522 - val_loss: 0.2963 - val_accuracy: 0.9427\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4808 - accuracy: 0.8796 - val_loss: 0.2585 - val_accuracy: 0.9291\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.7247 - accuracy: 0.8628 - val_loss: 0.3212 - val_accuracy: 0.9316\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7733 - accuracy: 0.8636 - val_loss: 0.2758 - val_accuracy: 0.9188\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4564 - accuracy: 0.8753 - val_loss: 0.1768 - val_accuracy: 0.9385\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4232 - accuracy: 0.8901 - val_loss: 0.3054 - val_accuracy: 0.9231\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3355 - accuracy: 0.9038 - val_loss: 0.2426 - val_accuracy: 0.9316\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4379 - accuracy: 0.8927 - val_loss: 0.2148 - val_accuracy: 0.9504\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2513 - accuracy: 0.9049 - val_loss: 0.2726 - val_accuracy: 0.9436\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2537 - accuracy: 0.9109 - val_loss: 0.2240 - val_accuracy: 0.9325\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.2303 - accuracy: 0.9191\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 67ms/step - loss: 7.0585 - accuracy: 0.9029 - val_loss: 0.2518 - val_accuracy: 0.9658\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.7114 - accuracy: 0.9439 - val_loss: 0.2129 - val_accuracy: 0.9573\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.2507 - accuracy: 0.9587 - val_loss: 0.4143 - val_accuracy: 0.9359\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2156 - accuracy: 0.9630 - val_loss: 0.2391 - val_accuracy: 0.9650\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2151 - accuracy: 0.9698 - val_loss: 0.2343 - val_accuracy: 0.9726\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1280 - accuracy: 0.9769 - val_loss: 0.2240 - val_accuracy: 0.9667\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1229 - accuracy: 0.9789 - val_loss: 0.2216 - val_accuracy: 0.9735\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3396 - accuracy: 0.9625\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 5.1905 - accuracy: 0.8898 - val_loss: 0.1123 - val_accuracy: 0.9581\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1789 - accuracy: 0.9539 - val_loss: 0.1658 - val_accuracy: 0.9368\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1481 - accuracy: 0.9599 - val_loss: 0.1011 - val_accuracy: 0.9496\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1277 - accuracy: 0.9653 - val_loss: 0.1315 - val_accuracy: 0.9615\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1184 - accuracy: 0.9741 - val_loss: 0.1626 - val_accuracy: 0.9667\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0732 - accuracy: 0.9795 - val_loss: 0.1735 - val_accuracy: 0.9692\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0633 - accuracy: 0.9829 - val_loss: 0.1488 - val_accuracy: 0.9692\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0708 - accuracy: 0.9835 - val_loss: 0.4607 - val_accuracy: 0.9376\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.4648 - accuracy: 0.9412\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 31.8054 - accuracy: 0.7642 - val_loss: 0.3771 - val_accuracy: 0.8778\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.0739 - accuracy: 0.8013 - val_loss: 0.3102 - val_accuracy: 0.9111\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7522 - accuracy: 0.8576 - val_loss: 0.3315 - val_accuracy: 0.9128\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4593 - accuracy: 0.8642 - val_loss: 0.2272 - val_accuracy: 0.9214\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5460 - accuracy: 0.8838 - val_loss: 0.2311 - val_accuracy: 0.9325\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3775 - accuracy: 0.8895 - val_loss: 0.2213 - val_accuracy: 0.9342\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3279 - accuracy: 0.8890 - val_loss: 0.4836 - val_accuracy: 0.8675\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3218 - accuracy: 0.8890 - val_loss: 0.2999 - val_accuracy: 0.9162\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3389 - accuracy: 0.9018 - val_loss: 0.2942 - val_accuracy: 0.9197\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2922 - accuracy: 0.9009 - val_loss: 0.2199 - val_accuracy: 0.9385\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2846 - accuracy: 0.9097 - val_loss: 0.2344 - val_accuracy: 0.9444\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2675 - accuracy: 0.9092 - val_loss: 0.2771 - val_accuracy: 0.9462\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2484 - accuracy: 0.9137 - val_loss: 0.2220 - val_accuracy: 0.9453\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2227 - accuracy: 0.9117 - val_loss: 0.1916 - val_accuracy: 0.9427\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3272 - accuracy: 0.9069 - val_loss: 1.3594 - val_accuracy: 0.8821\n",
      "Epoch 16/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2548 - accuracy: 0.9174 - val_loss: 0.3057 - val_accuracy: 0.9368\n",
      "Epoch 17/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2191 - accuracy: 0.9180 - val_loss: 0.2803 - val_accuracy: 0.9291\n",
      "Epoch 18/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2477 - accuracy: 0.9183 - val_loss: 0.2617 - val_accuracy: 0.9299\n",
      "Epoch 19/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2011 - accuracy: 0.9188 - val_loss: 0.2695 - val_accuracy: 0.9265\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.2651 - accuracy: 0.9165\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 4.2981 - accuracy: 0.9095 - val_loss: 0.1886 - val_accuracy: 0.9521\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3424 - accuracy: 0.9425 - val_loss: 0.4391 - val_accuracy: 0.9419\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3602 - accuracy: 0.9516 - val_loss: 0.3000 - val_accuracy: 0.9513\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2463 - accuracy: 0.9581 - val_loss: 0.2089 - val_accuracy: 0.9530\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2921 - accuracy: 0.9621 - val_loss: 0.3246 - val_accuracy: 0.9598\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1801 - accuracy: 0.9735 - val_loss: 0.2257 - val_accuracy: 0.9650\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2343 - accuracy: 0.9659\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 64ms/step - loss: 7.0779 - accuracy: 0.9052 - val_loss: 0.2395 - val_accuracy: 0.9632\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4469 - accuracy: 0.9428 - val_loss: 0.2457 - val_accuracy: 0.9436\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3090 - accuracy: 0.9490 - val_loss: 0.2538 - val_accuracy: 0.9573\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2268 - accuracy: 0.9670 - val_loss: 0.1341 - val_accuracy: 0.9650\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1896 - accuracy: 0.9664 - val_loss: 0.1597 - val_accuracy: 0.9650\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1155 - accuracy: 0.9735 - val_loss: 0.3011 - val_accuracy: 0.9632\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1195 - accuracy: 0.9792 - val_loss: 0.1892 - val_accuracy: 0.9650\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0687 - accuracy: 0.9878 - val_loss: 0.7321 - val_accuracy: 0.9231\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.1283 - accuracy: 0.9832 - val_loss: 0.2364 - val_accuracy: 0.9615\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2591 - accuracy: 0.9668\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 34.1420 - accuracy: 0.8260 - val_loss: 6.5234 - val_accuracy: 0.7906\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.0417 - accuracy: 0.8109 - val_loss: 0.4527 - val_accuracy: 0.8855\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.3569 - accuracy: 0.8146 - val_loss: 0.7893 - val_accuracy: 0.8829\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.8484 - accuracy: 0.8442 - val_loss: 0.3641 - val_accuracy: 0.9342\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5679 - accuracy: 0.8494 - val_loss: 0.3096 - val_accuracy: 0.8530\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6254 - accuracy: 0.8610 - val_loss: 0.2778 - val_accuracy: 0.9205\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6040 - accuracy: 0.8687 - val_loss: 0.2459 - val_accuracy: 0.9444\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5903 - accuracy: 0.8895 - val_loss: 0.5944 - val_accuracy: 0.9308\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3943 - accuracy: 0.8904 - val_loss: 0.4043 - val_accuracy: 0.9239\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.5431 - accuracy: 0.8927 - val_loss: 0.2627 - val_accuracy: 0.9427\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2999 - accuracy: 0.9029 - val_loss: 0.3245 - val_accuracy: 0.9274\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3497 - accuracy: 0.9026 - val_loss: 0.1980 - val_accuracy: 0.9376\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3089 - accuracy: 0.9077 - val_loss: 0.2257 - val_accuracy: 0.9410\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3229 - accuracy: 0.9029 - val_loss: 0.2686 - val_accuracy: 0.8607\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3134 - accuracy: 0.8875 - val_loss: 0.2670 - val_accuracy: 0.9393\n",
      "Epoch 16/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3329 - accuracy: 0.9109 - val_loss: 0.2727 - val_accuracy: 0.9179\n",
      "Epoch 17/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.3871 - accuracy: 0.9137 - val_loss: 0.3161 - val_accuracy: 0.9479\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.3226 - accuracy: 0.9284\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 63ms/step - loss: 5.5255 - accuracy: 0.9083 - val_loss: 2.3215 - val_accuracy: 0.8658\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5957 - accuracy: 0.9416 - val_loss: 0.2005 - val_accuracy: 0.9521\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.2982 - accuracy: 0.9562 - val_loss: 0.8956 - val_accuracy: 0.9034\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2427 - accuracy: 0.9627 - val_loss: 0.2869 - val_accuracy: 0.9615\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1505 - accuracy: 0.9735 - val_loss: 0.2419 - val_accuracy: 0.9581\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1190 - accuracy: 0.9789 - val_loss: 0.1820 - val_accuracy: 0.9692\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1288 - accuracy: 0.9769 - val_loss: 0.2276 - val_accuracy: 0.9650\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1379 - accuracy: 0.9795 - val_loss: 0.2611 - val_accuracy: 0.9658\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0857 - accuracy: 0.9843 - val_loss: 0.1982 - val_accuracy: 0.9598\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0501 - accuracy: 0.9903 - val_loss: 0.2732 - val_accuracy: 0.9667\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0878 - accuracy: 0.9878 - val_loss: 0.3265 - val_accuracy: 0.9684\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.4322 - accuracy: 0.9659\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 66ms/step - loss: 5.8005 - accuracy: 0.9040 - val_loss: 0.1939 - val_accuracy: 0.9607\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4831 - accuracy: 0.9422 - val_loss: 0.1197 - val_accuracy: 0.9658\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5178 - accuracy: 0.9445 - val_loss: 0.4212 - val_accuracy: 0.9103\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2105 - accuracy: 0.9630 - val_loss: 0.2047 - val_accuracy: 0.9564\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1629 - accuracy: 0.9718 - val_loss: 0.1524 - val_accuracy: 0.9701\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0985 - accuracy: 0.9772 - val_loss: 0.1797 - val_accuracy: 0.9521\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0924 - accuracy: 0.9798 - val_loss: 0.3391 - val_accuracy: 0.9632\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3561 - accuracy: 0.9634\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 44.8294 - accuracy: 0.8349 - val_loss: 1.7484 - val_accuracy: 0.8615\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.4954 - accuracy: 0.8337 - val_loss: 0.3460 - val_accuracy: 0.9120\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9340 - accuracy: 0.8588 - val_loss: 18.0977 - val_accuracy: 0.4231\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.0598 - accuracy: 0.8764 - val_loss: 0.5944 - val_accuracy: 0.8675\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6103 - accuracy: 0.8827 - val_loss: 6.9574 - val_accuracy: 0.7846\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7321 - accuracy: 0.8944 - val_loss: 0.2525 - val_accuracy: 0.9248\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5323 - accuracy: 0.8995 - val_loss: 0.2071 - val_accuracy: 0.9410\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3628 - accuracy: 0.9038 - val_loss: 1.2827 - val_accuracy: 0.8991\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5083 - accuracy: 0.9018 - val_loss: 0.2659 - val_accuracy: 0.9419\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3352 - accuracy: 0.9134 - val_loss: 0.2294 - val_accuracy: 0.9427\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2718 - accuracy: 0.9015 - val_loss: 0.3340 - val_accuracy: 0.8829\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3124 - accuracy: 0.9140 - val_loss: 0.2900 - val_accuracy: 0.9282\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.3292 - accuracy: 0.9097\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 63ms/step - loss: 4.6505 - accuracy: 0.8941 - val_loss: 0.1132 - val_accuracy: 0.9650\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2885 - accuracy: 0.9348 - val_loss: 0.1169 - val_accuracy: 0.9581\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2122 - accuracy: 0.9579 - val_loss: 0.1149 - val_accuracy: 0.9658\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1929 - accuracy: 0.9653 - val_loss: 0.1238 - val_accuracy: 0.9667\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1344 - accuracy: 0.9667 - val_loss: 0.1483 - val_accuracy: 0.9684\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1237 - accuracy: 0.9695 - val_loss: 0.1732 - val_accuracy: 0.9650\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.1763 - accuracy: 0.9651\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 3.5512 - accuracy: 0.8969 - val_loss: 0.1088 - val_accuracy: 0.9632\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3382 - accuracy: 0.9388 - val_loss: 0.1444 - val_accuracy: 0.9650\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2685 - accuracy: 0.9530 - val_loss: 0.1174 - val_accuracy: 0.9650\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1798 - accuracy: 0.9613 - val_loss: 0.1091 - val_accuracy: 0.9632\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1371 - accuracy: 0.9633 - val_loss: 0.1078 - val_accuracy: 0.9650\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1576 - accuracy: 0.9721 - val_loss: 0.2609 - val_accuracy: 0.9547\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1248 - accuracy: 0.9718 - val_loss: 0.1630 - val_accuracy: 0.9718\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1027 - accuracy: 0.9795 - val_loss: 0.1423 - val_accuracy: 0.9632\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1162 - accuracy: 0.9758 - val_loss: 0.2872 - val_accuracy: 0.9564\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0682 - accuracy: 0.9835 - val_loss: 0.2619 - val_accuracy: 0.9718\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2939 - accuracy: 0.9693\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 32.7364 - accuracy: 0.7799 - val_loss: 0.6494 - val_accuracy: 0.8624\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.0264 - accuracy: 0.8425 - val_loss: 0.3572 - val_accuracy: 0.8838\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6917 - accuracy: 0.8525 - val_loss: 2.5450 - val_accuracy: 0.7470\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7217 - accuracy: 0.8645 - val_loss: 0.2156 - val_accuracy: 0.9385\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5135 - accuracy: 0.8781 - val_loss: 0.2378 - val_accuracy: 0.9265\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5457 - accuracy: 0.8935 - val_loss: 0.2021 - val_accuracy: 0.9436\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2962 - accuracy: 0.8927 - val_loss: 0.2102 - val_accuracy: 0.9256\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5844 - accuracy: 0.8878 - val_loss: 0.2292 - val_accuracy: 0.9325\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3046 - accuracy: 0.9092 - val_loss: 0.2125 - val_accuracy: 0.9427\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2935 - accuracy: 0.9055 - val_loss: 0.1821 - val_accuracy: 0.9393\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3768 - accuracy: 0.9058 - val_loss: 0.3306 - val_accuracy: 0.9239\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.2855 - accuracy: 0.9100 - val_loss: 0.2432 - val_accuracy: 0.9444\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4417 - accuracy: 0.9100 - val_loss: 0.2262 - val_accuracy: 0.9402\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2612 - accuracy: 0.9112 - val_loss: 0.6971 - val_accuracy: 0.8803\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2322 - accuracy: 0.9126 - val_loss: 0.2271 - val_accuracy: 0.9222\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.2292 - accuracy: 0.9106\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 5.2339 - accuracy: 0.9003 - val_loss: 2.4395 - val_accuracy: 0.7444\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4162 - accuracy: 0.9354 - val_loss: 0.1274 - val_accuracy: 0.9521\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2342 - accuracy: 0.9573 - val_loss: 0.1897 - val_accuracy: 0.9632\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2082 - accuracy: 0.9667 - val_loss: 0.1114 - val_accuracy: 0.9667\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1628 - accuracy: 0.9712 - val_loss: 0.1850 - val_accuracy: 0.9598\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1736 - accuracy: 0.9704 - val_loss: 0.2367 - val_accuracy: 0.9684\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1247 - accuracy: 0.9769 - val_loss: 0.1613 - val_accuracy: 0.9624\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1030 - accuracy: 0.9792 - val_loss: 0.1557 - val_accuracy: 0.9590\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0777 - accuracy: 0.9832 - val_loss: 0.1644 - val_accuracy: 0.9632\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2426 - accuracy: 0.9651\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 6.2684 - accuracy: 0.9046 - val_loss: 0.3114 - val_accuracy: 0.9632\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5714 - accuracy: 0.9399 - val_loss: 0.1145 - val_accuracy: 0.9590\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3918 - accuracy: 0.9502 - val_loss: 0.3050 - val_accuracy: 0.9479\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.3481 - accuracy: 0.9584 - val_loss: 0.1984 - val_accuracy: 0.9624\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.2116 - accuracy: 0.9644 - val_loss: 0.3375 - val_accuracy: 0.9521\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1948 - accuracy: 0.9755 - val_loss: 0.2984 - val_accuracy: 0.9632\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1874 - accuracy: 0.9764 - val_loss: 0.5623 - val_accuracy: 0.9462\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.5457 - accuracy: 0.9566\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 47.9494 - accuracy: 0.8215 - val_loss: 0.6143 - val_accuracy: 0.8906\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.4755 - accuracy: 0.8417 - val_loss: 0.6500 - val_accuracy: 0.9282\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.0447 - accuracy: 0.8619 - val_loss: 0.3603 - val_accuracy: 0.9077\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9861 - accuracy: 0.8687 - val_loss: 0.2701 - val_accuracy: 0.9368\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4845 - accuracy: 0.8625 - val_loss: 0.2317 - val_accuracy: 0.9231\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6224 - accuracy: 0.8716 - val_loss: 0.1943 - val_accuracy: 0.9419\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6730 - accuracy: 0.8739 - val_loss: 0.2219 - val_accuracy: 0.9325\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3748 - accuracy: 0.8790 - val_loss: 0.1716 - val_accuracy: 0.9470\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6239 - accuracy: 0.8978 - val_loss: 0.2144 - val_accuracy: 0.9402\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3409 - accuracy: 0.8898 - val_loss: 0.2008 - val_accuracy: 0.9410\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3335 - accuracy: 0.8949 - val_loss: 1.2664 - val_accuracy: 0.9085\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3643 - accuracy: 0.8981 - val_loss: 0.2370 - val_accuracy: 0.9350\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3478 - accuracy: 0.9049 - val_loss: 0.2122 - val_accuracy: 0.9427\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.2231 - accuracy: 0.9276\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 63ms/step - loss: 6.3019 - accuracy: 0.8909 - val_loss: 0.1243 - val_accuracy: 0.9521\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2751 - accuracy: 0.9399 - val_loss: 1.3570 - val_accuracy: 0.8333\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2101 - accuracy: 0.9527 - val_loss: 0.0978 - val_accuracy: 0.9675\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1552 - accuracy: 0.9681 - val_loss: 0.1378 - val_accuracy: 0.9590\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1668 - accuracy: 0.9655 - val_loss: 0.1840 - val_accuracy: 0.9556\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1507 - accuracy: 0.9727 - val_loss: 0.2056 - val_accuracy: 0.9598\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0877 - accuracy: 0.9775 - val_loss: 0.2816 - val_accuracy: 0.9590\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0763 - accuracy: 0.9809 - val_loss: 0.1735 - val_accuracy: 0.9667\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2144 - accuracy: 0.9659\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 10s 64ms/step - loss: 3.6831 - accuracy: 0.9055 - val_loss: 0.1348 - val_accuracy: 0.9590\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3083 - accuracy: 0.9399 - val_loss: 0.1685 - val_accuracy: 0.9573\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2841 - accuracy: 0.9482 - val_loss: 0.3154 - val_accuracy: 0.9188\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.2603 - accuracy: 0.9607 - val_loss: 0.1994 - val_accuracy: 0.9684\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2296 - accuracy: 0.9661 - val_loss: 0.1753 - val_accuracy: 0.9675\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1870 - accuracy: 0.9707 - val_loss: 0.3587 - val_accuracy: 0.9427\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3663 - accuracy: 0.9506\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 43.0354 - accuracy: 0.8181 - val_loss: 0.6967 - val_accuracy: 0.8538\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.4150 - accuracy: 0.8274 - val_loss: 0.4307 - val_accuracy: 0.8641\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.6348 - accuracy: 0.8223 - val_loss: 0.2550 - val_accuracy: 0.9205\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.8207 - accuracy: 0.8665 - val_loss: 0.3606 - val_accuracy: 0.9274\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5540 - accuracy: 0.8704 - val_loss: 0.2802 - val_accuracy: 0.9145\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6871 - accuracy: 0.8807 - val_loss: 0.4976 - val_accuracy: 0.8932\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.6852 - accuracy: 0.8998 - val_loss: 0.4870 - val_accuracy: 0.8940\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5191 - accuracy: 0.8855 - val_loss: 0.3278 - val_accuracy: 0.9239\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.3841 - accuracy: 0.9250\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 3.8221 - accuracy: 0.8952 - val_loss: 0.1122 - val_accuracy: 0.9573\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3051 - accuracy: 0.9319 - val_loss: 0.2049 - val_accuracy: 0.9530\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2574 - accuracy: 0.9502 - val_loss: 0.1078 - val_accuracy: 0.9641\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2486 - accuracy: 0.9527 - val_loss: 0.0958 - val_accuracy: 0.9667\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1982 - accuracy: 0.9630 - val_loss: 0.2908 - val_accuracy: 0.9496\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1432 - accuracy: 0.9712 - val_loss: 0.1434 - val_accuracy: 0.9658\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0885 - accuracy: 0.9735 - val_loss: 0.1405 - val_accuracy: 0.9598\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0856 - accuracy: 0.9826 - val_loss: 0.1832 - val_accuracy: 0.9692\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0631 - accuracy: 0.9823 - val_loss: 0.2878 - val_accuracy: 0.9650\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3210 - accuracy: 0.9625\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 5.0733 - accuracy: 0.8983 - val_loss: 1.6343 - val_accuracy: 0.8709\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3532 - accuracy: 0.9368 - val_loss: 0.1777 - val_accuracy: 0.9590\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3469 - accuracy: 0.9510 - val_loss: 0.1813 - val_accuracy: 0.9573\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2116 - accuracy: 0.9616 - val_loss: 0.1481 - val_accuracy: 0.9650\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1712 - accuracy: 0.9664 - val_loss: 0.1195 - val_accuracy: 0.9581\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1208 - accuracy: 0.9767 - val_loss: 0.1316 - val_accuracy: 0.9701\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1014 - accuracy: 0.9781 - val_loss: 0.1740 - val_accuracy: 0.9650\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.1140 - accuracy: 0.9821 - val_loss: 0.1294 - val_accuracy: 0.9692\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1465 - accuracy: 0.9806 - val_loss: 0.2691 - val_accuracy: 0.9692\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0783 - accuracy: 0.9860 - val_loss: 0.2355 - val_accuracy: 0.9684\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2917 - accuracy: 0.9634\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 54ms/step - loss: 55.7034 - accuracy: 0.8126 - val_loss: 0.8399 - val_accuracy: 0.8761\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.9311 - accuracy: 0.8240 - val_loss: 0.2989 - val_accuracy: 0.8915\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.2081 - accuracy: 0.8101 - val_loss: 0.7516 - val_accuracy: 0.7846\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9483 - accuracy: 0.8405 - val_loss: 0.5564 - val_accuracy: 0.8940\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7808 - accuracy: 0.8588 - val_loss: 0.2397 - val_accuracy: 0.9068\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7625 - accuracy: 0.8733 - val_loss: 0.3035 - val_accuracy: 0.9197\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4605 - accuracy: 0.8793 - val_loss: 0.5142 - val_accuracy: 0.9222\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.0687 - accuracy: 0.8844 - val_loss: 0.2402 - val_accuracy: 0.9487\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5449 - accuracy: 0.8955 - val_loss: 0.9719 - val_accuracy: 0.8855\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4803 - accuracy: 0.8929 - val_loss: 0.3384 - val_accuracy: 0.9308\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.3362 - accuracy: 0.9208\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 3.9732 - accuracy: 0.9032 - val_loss: 0.1357 - val_accuracy: 0.9513\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3396 - accuracy: 0.9385 - val_loss: 0.1810 - val_accuracy: 0.9547\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2826 - accuracy: 0.9544 - val_loss: 0.0997 - val_accuracy: 0.9624\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2760 - accuracy: 0.9556 - val_loss: 0.2032 - val_accuracy: 0.9590\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1763 - accuracy: 0.9655 - val_loss: 0.1431 - val_accuracy: 0.9624\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1626 - accuracy: 0.9667 - val_loss: 0.1889 - val_accuracy: 0.9598\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1229 - accuracy: 0.9778 - val_loss: 0.3782 - val_accuracy: 0.9393\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1163 - accuracy: 0.9781 - val_loss: 0.1944 - val_accuracy: 0.9650\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2879 - accuracy: 0.9608\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 3.6216 - accuracy: 0.8964 - val_loss: 0.1874 - val_accuracy: 0.9615\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3525 - accuracy: 0.9405 - val_loss: 0.2653 - val_accuracy: 0.9521\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2207 - accuracy: 0.9496 - val_loss: 0.3809 - val_accuracy: 0.9316\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1946 - accuracy: 0.9621 - val_loss: 0.0913 - val_accuracy: 0.9650\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1716 - accuracy: 0.9610 - val_loss: 0.1268 - val_accuracy: 0.9675\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1301 - accuracy: 0.9732 - val_loss: 0.1185 - val_accuracy: 0.9615\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0976 - accuracy: 0.9764 - val_loss: 0.1501 - val_accuracy: 0.9624\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0910 - accuracy: 0.9784 - val_loss: 0.1360 - val_accuracy: 0.9615\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.0653 - accuracy: 0.9809 - val_loss: 0.1261 - val_accuracy: 0.9701\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.1926 - accuracy: 0.9702\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 53ms/step - loss: 43.2392 - accuracy: 0.8255 - val_loss: 0.2931 - val_accuracy: 0.9188\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.7254 - accuracy: 0.8104 - val_loss: 0.3371 - val_accuracy: 0.9265\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.9715 - accuracy: 0.8069 - val_loss: 0.3809 - val_accuracy: 0.9009\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7675 - accuracy: 0.8633 - val_loss: 0.3827 - val_accuracy: 0.9368\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7051 - accuracy: 0.8522 - val_loss: 0.2702 - val_accuracy: 0.9017\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5891 - accuracy: 0.8616 - val_loss: 0.2969 - val_accuracy: 0.9453\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4528 - accuracy: 0.8813 - val_loss: 0.2984 - val_accuracy: 0.9179\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4615 - accuracy: 0.8667 - val_loss: 0.2183 - val_accuracy: 0.9299\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.5769 - accuracy: 0.8778 - val_loss: 0.2867 - val_accuracy: 0.9188\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4148 - accuracy: 0.8796 - val_loss: 0.2753 - val_accuracy: 0.9410\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3351 - accuracy: 0.8878 - val_loss: 0.2212 - val_accuracy: 0.9325\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3487 - accuracy: 0.8850 - val_loss: 0.4011 - val_accuracy: 0.9291\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3275 - accuracy: 0.8787 - val_loss: 0.2814 - val_accuracy: 0.9333\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.2752 - accuracy: 0.9276\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 63ms/step - loss: 5.5996 - accuracy: 0.8958 - val_loss: 0.8169 - val_accuracy: 0.9188\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4205 - accuracy: 0.9416 - val_loss: 0.1736 - val_accuracy: 0.9564\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.3726 - accuracy: 0.9476 - val_loss: 0.1484 - val_accuracy: 0.9504\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.1879 - accuracy: 0.9579 - val_loss: 0.3359 - val_accuracy: 0.9402\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1955 - accuracy: 0.9667 - val_loss: 0.1009 - val_accuracy: 0.9658\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1460 - accuracy: 0.9698 - val_loss: 0.1941 - val_accuracy: 0.9658\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1041 - accuracy: 0.9775 - val_loss: 0.1146 - val_accuracy: 0.9632\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0973 - accuracy: 0.9769 - val_loss: 0.2443 - val_accuracy: 0.9675\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1051 - accuracy: 0.9761 - val_loss: 0.2221 - val_accuracy: 0.9761\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0802 - accuracy: 0.9843 - val_loss: 0.1641 - val_accuracy: 0.9684\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2049 - accuracy: 0.9676\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 64ms/step - loss: 4.9846 - accuracy: 0.9055 - val_loss: 0.2070 - val_accuracy: 0.9581\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.5114 - accuracy: 0.9365 - val_loss: 0.2759 - val_accuracy: 0.9359\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4858 - accuracy: 0.9470 - val_loss: 0.1821 - val_accuracy: 0.9615\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3021 - accuracy: 0.9638 - val_loss: 0.1524 - val_accuracy: 0.9667\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2895 - accuracy: 0.9604 - val_loss: 0.1707 - val_accuracy: 0.9615\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1517 - accuracy: 0.9732 - val_loss: 0.3266 - val_accuracy: 0.9615\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1840 - accuracy: 0.9727 - val_loss: 0.2726 - val_accuracy: 0.9684\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1309 - accuracy: 0.9786 - val_loss: 0.9530 - val_accuracy: 0.9205\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1505 - accuracy: 0.9775 - val_loss: 0.2197 - val_accuracy: 0.9684\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3066 - accuracy: 0.9651\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 55ms/step - loss: 49.0540 - accuracy: 0.8331 - val_loss: 2.3652 - val_accuracy: 0.7590\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.6769 - accuracy: 0.8292 - val_loss: 0.5457 - val_accuracy: 0.9051\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.3303 - accuracy: 0.8565 - val_loss: 0.4354 - val_accuracy: 0.9128\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.1691 - accuracy: 0.8716 - val_loss: 0.2126 - val_accuracy: 0.9444\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.8707 - accuracy: 0.8841 - val_loss: 0.2381 - val_accuracy: 0.9248\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7014 - accuracy: 0.8776 - val_loss: 0.2469 - val_accuracy: 0.9410\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4509 - accuracy: 0.9001 - val_loss: 0.3695 - val_accuracy: 0.9274\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3416 - accuracy: 0.9049 - val_loss: 0.2785 - val_accuracy: 0.8932\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.4178 - accuracy: 0.8995 - val_loss: 0.1885 - val_accuracy: 0.9513\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3267 - accuracy: 0.9117 - val_loss: 0.2516 - val_accuracy: 0.9487\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3854 - accuracy: 0.9109 - val_loss: 0.3535 - val_accuracy: 0.9496\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.3550 - accuracy: 0.9052 - val_loss: 0.1983 - val_accuracy: 0.9316\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2312 - accuracy: 0.9100 - val_loss: 0.1991 - val_accuracy: 0.9479\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.2124 - accuracy: 0.9265 - val_loss: 0.3023 - val_accuracy: 0.9479\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.3201 - accuracy: 0.9310\n",
      "Epoch 1/500\n",
      "110/110 [==============================] - 9s 63ms/step - loss: 7.7946 - accuracy: 0.9023 - val_loss: 0.5922 - val_accuracy: 0.9598\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5696 - accuracy: 0.9408 - val_loss: 0.4451 - val_accuracy: 0.9504\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.3358 - accuracy: 0.9507 - val_loss: 0.2238 - val_accuracy: 0.9624\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2428 - accuracy: 0.9624 - val_loss: 0.2759 - val_accuracy: 0.9479\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2267 - accuracy: 0.9630 - val_loss: 0.3114 - val_accuracy: 0.9564\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2153 - accuracy: 0.9675 - val_loss: 0.2764 - val_accuracy: 0.9658\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 7s 57ms/step - loss: 0.2071 - accuracy: 0.9724 - val_loss: 0.1382 - val_accuracy: 0.9735\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1161 - accuracy: 0.9784 - val_loss: 0.2107 - val_accuracy: 0.9684\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.2000 - accuracy: 0.9784 - val_loss: 0.1977 - val_accuracy: 0.9718\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1118 - accuracy: 0.9821 - val_loss: 0.2615 - val_accuracy: 0.9684\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.1352 - accuracy: 0.9798 - val_loss: 0.3116 - val_accuracy: 0.9709\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0855 - accuracy: 0.9878 - val_loss: 0.2127 - val_accuracy: 0.9744\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.2621 - accuracy: 0.9693\n"
     ]
    }
   ],
   "source": [
    "drop_rate = 0.02\n",
    "result_dict_res = {}\n",
    "result_dict_incept = {}\n",
    "result_dict_resv2 = {}\n",
    "while drop_rate <= 0.5:\n",
    "    resnet50_mod = build_resnet50_model(drop_rate)\n",
    "    fitted_resnet50_mod = fit_model(resnet50_mod, train_data, val_data)\n",
    "    result_dict_res[drop_rate] = fitted_resnet50_mod.evaluate(test_data)\n",
    "\n",
    "    inceptionV3_mod = build_inceptionV3_model()\n",
    "    fitted_inceptionV3_mod = fit_model(inceptionV3_mod, train_data, val_data)\n",
    "    result_dict_incept[drop_rate] = fitted_inceptionV3_mod.evaluate(test_data)\n",
    "\n",
    "    resnet50V2_mod = build_resnet50_model(drop_rate)\n",
    "    fitted_resnet50V2_mod = fit_model(resnet50V2_mod, train_data, val_data)\n",
    "    result_dict_resv2[drop_rate] = fitted_resnet50V2_mod.evaluate(test_data)\n",
    "    drop_rate += 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.02: [0.37676718831062317, 0.9608176946640015],\n",
       " 0.04: [0.25560250878334045, 0.9676320552825928],\n",
       " 0.06: [0.3517296314239502, 0.959114134311676],\n",
       " 0.08: [0.23496900498867035, 0.9650766849517822],\n",
       " 0.1: [0.3323254883289337, 0.9667802453041077],\n",
       " 0.12000000000000001: [0.2284497618675232, 0.9701873660087585],\n",
       " 0.14: [0.4451943337917328, 0.9667802453041077],\n",
       " 0.16: [0.4457070827484131, 0.9650766849517822],\n",
       " 0.18: [0.24320724606513977, 0.9650766849517822],\n",
       " 0.19999999999999998: [0.23714368045330048, 0.9693356156349182],\n",
       " 0.21999999999999997: [0.9427320957183838, 0.9522998332977295],\n",
       " 0.23999999999999996: [0.2084566354751587, 0.9684838056564331],\n",
       " 0.25999999999999995: [0.4985183775424957, 0.9684838056564331],\n",
       " 0.27999999999999997: [0.3069182336330414, 0.9701873660087585],\n",
       " 0.3: [0.33955931663513184, 0.9625213146209717],\n",
       " 0.32: [0.23426426947116852, 0.9659284353256226],\n",
       " 0.34: [0.4322158992290497, 0.9659284353256226],\n",
       " 0.36000000000000004: [0.17634180188179016, 0.9650766849517822],\n",
       " 0.38000000000000006: [0.2425622045993805, 0.9650766849517822],\n",
       " 0.4000000000000001: [0.21443217992782593, 0.9659284353256226],\n",
       " 0.4200000000000001: [0.32097291946411133, 0.9625213146209717],\n",
       " 0.4400000000000001: [0.2878609001636505, 0.9608176946640015],\n",
       " 0.46000000000000013: [0.20489218831062317, 0.9676320552825928],\n",
       " 0.48000000000000015: [0.2620502710342407, 0.9693356156349182]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_resv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.02: [0.30146533250808716, 0.9190800786018372],\n",
       " 0.04: [0.21286943554878235, 0.9165247082710266],\n",
       " 0.06: [0.3826604187488556, 0.8935264348983765],\n",
       " 0.08: [0.2270691841840744, 0.9327086806297302],\n",
       " 0.1: [0.211821511387825, 0.9207836389541626],\n",
       " 0.12000000000000001: [1.027580738067627, 0.8713799118995667],\n",
       " 0.14: [0.21643109619617462, 0.9156728982925415],\n",
       " 0.16: [0.3614528477191925, 0.9173765182495117],\n",
       " 0.18: [0.4079737663269043, 0.9293015599250793],\n",
       " 0.19999999999999998: [0.35292932391166687, 0.913117527961731],\n",
       " 0.21999999999999997: [0.24162092804908752, 0.9284497499465942],\n",
       " 0.23999999999999996: [0.25929906964302063, 0.9318568706512451],\n",
       " 0.25999999999999995: [0.3191666603088379, 0.9310051202774048],\n",
       " 0.27999999999999997: [0.25223320722579956, 0.8756388425827026],\n",
       " 0.3: [0.23034514486789703, 0.9190800786018372],\n",
       " 0.32: [0.26506510376930237, 0.9165247082710266],\n",
       " 0.34: [0.32264137268066406, 0.9284497499465942],\n",
       " 0.36000000000000004: [0.32922670245170593, 0.9097104072570801],\n",
       " 0.38000000000000006: [0.2291693091392517, 0.9105621576309204],\n",
       " 0.4000000000000001: [0.22305913269519806, 0.9275979399681091],\n",
       " 0.4200000000000001: [0.3841353952884674, 0.9250425696372986],\n",
       " 0.4400000000000001: [0.3361860513687134, 0.9207836389541626],\n",
       " 0.46000000000000013: [0.27519723773002625, 0.9275979399681091],\n",
       " 0.48000000000000015: [0.32007864117622375, 0.9310051202774048]}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_incept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.02: [0.18458567559719086, 0.9710391759872437],\n",
       " 0.04: [0.24346186220645905, 0.9650766849517822],\n",
       " 0.06: [0.547414243221283, 0.9531516432762146],\n",
       " 0.08: [0.3533893823623657, 0.9667802453041077],\n",
       " 0.1: [0.2170780748128891, 0.9659284353256226],\n",
       " 0.12000000000000001: [0.3375418186187744, 0.9710391759872437],\n",
       " 0.14: [0.34327489137649536, 0.9599659442901611],\n",
       " 0.16: [0.49896302819252014, 0.9667802453041077],\n",
       " 0.18: [0.320851594209671, 0.9676320552825928],\n",
       " 0.19999999999999998: [0.709280252456665, 0.9667802453041077],\n",
       " 0.21999999999999997: [0.3050961494445801, 0.9522998332977295],\n",
       " 0.23999999999999996: [0.34127116203308105, 0.9625213146209717],\n",
       " 0.25999999999999995: [0.17326131463050842, 0.9667802453041077],\n",
       " 0.27999999999999997: [0.5522371530532837, 0.9233390092849731],\n",
       " 0.3: [0.3454062342643738, 0.9642248749732971],\n",
       " 0.32: [0.4648095965385437, 0.941226601600647],\n",
       " 0.34: [0.2590581476688385, 0.9667802453041077],\n",
       " 0.36000000000000004: [0.3561047613620758, 0.963373064994812],\n",
       " 0.38000000000000006: [0.2939269244670868, 0.9693356156349182],\n",
       " 0.4000000000000001: [0.5456624627113342, 0.9565587639808655],\n",
       " 0.4200000000000001: [0.3663488030433655, 0.950596272945404],\n",
       " 0.4400000000000001: [0.2917385697364807, 0.963373064994812],\n",
       " 0.46000000000000013: [0.19261491298675537, 0.9701873660087585],\n",
       " 0.48000000000000015: [0.3065951466560364, 0.9650766849517822]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".971 accuracy with resnet 50 with dropout 0.12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "110/110 [==============================] - 6s 42ms/step - loss: 56.5407 - accuracy: 0.7232 - val_loss: 0.5894 - val_accuracy: 0.8667\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 4s 36ms/step - loss: 5.0247 - accuracy: 0.8394 - val_loss: 0.4208 - val_accuracy: 0.8855\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 4s 36ms/step - loss: 3.2675 - accuracy: 0.8465 - val_loss: 1.1285 - val_accuracy: 0.8786\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 4s 36ms/step - loss: 0.5286 - accuracy: 0.9035 - val_loss: 4.2272 - val_accuracy: 0.6684\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 4s 36ms/step - loss: 0.7715 - accuracy: 0.9075 - val_loss: 0.3630 - val_accuracy: 0.9120\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 4s 36ms/step - loss: 0.7415 - accuracy: 0.9291 - val_loss: 0.3351 - val_accuracy: 0.9231\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 0.2911 - accuracy: 0.9436 - val_loss: 10.1311 - val_accuracy: 0.7316\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 1.2757 - accuracy: 0.9445 - val_loss: 0.5790 - val_accuracy: 0.9179\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 0.4366 - accuracy: 0.9544 - val_loss: 0.8057 - val_accuracy: 0.9000\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 4s 36ms/step - loss: 1.1774 - accuracy: 0.9570 - val_loss: 0.8066 - val_accuracy: 0.9350\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 0.4586 - accuracy: 0.9641 - val_loss: 0.7834 - val_accuracy: 0.9222\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 0.3449 - accuracy: 0.9718 - val_loss: 1.4694 - val_accuracy: 0.9111\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 2.6998 - accuracy: 0.9507 - val_loss: 2.7552 - val_accuracy: 0.9282\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 0.3476 - accuracy: 0.9772 - val_loss: 3.2906 - val_accuracy: 0.9009\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 0.9603 - accuracy: 0.9749 - val_loss: 1.8463 - val_accuracy: 0.9291\n",
      "Epoch 16/500\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 4.4458 - accuracy: 0.9673 - val_loss: 2.6959 - val_accuracy: 0.9376\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.3066 - accuracy: 0.9651\n"
     ]
    }
   ],
   "source": [
    "# function to build the conv net base\n",
    "\n",
    "\n",
    "# complete this function\n",
    "def build_base_convnet_model():\n",
    "    \"\"\"Re-create the model from the first prompt, but with a different input shape\"\"\"\n",
    "    \n",
    "    # Return this variable\n",
    "    model = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    inputs = keras.Input(shape = (180, 180, 3))\n",
    "    x = keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu')(inputs)\n",
    "    x = keras.layers.MaxPooling2D(pool_size = 2)(x)\n",
    "    x = keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu')(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size = 2)(x)\n",
    "    x = keras.layers.Conv2D(filters = 128, kernel_size = 3, activation = 'relu')(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    outputs = keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_image_data(base_path: str) -> tuple:\n",
    "    \"\"\"Write a function that accepts a base path that contains all of the directories, and creates training,\n",
    "    validation and test sets\"\"\"\n",
    "    \n",
    "    # Return these variables from the function\n",
    "    train_data = keras.utils.image_dataset_from_directory(f'{base_path}/train', \n",
    "                                                          image_size = (180, 180),\n",
    "                                                          batch_size = 64)\n",
    "\n",
    "    validation_data = keras.utils.image_dataset_from_directory(f'{base_path}/val', \n",
    "                                                          image_size = (180, 180),\n",
    "                                                          batch_size = 64)\n",
    "    \n",
    "    test_data = keras.utils.image_dataset_from_directory(f'{base_path}/test', \n",
    "                                                          image_size = (180, 180),\n",
    "                                                          batch_size = 64)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    return train_data, validation_data, test_data\n",
    "\n",
    "def fit_convnet_model(model, train_set, validation_set):\n",
    "    \"\"\"Fit a model with the above stated criteria\"\"\"\n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience = 10)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    model.fit(train_set, \n",
    "              validation_data = validation_set, \n",
    "              callbacks = [early_stopping], \n",
    "              epochs = 500)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "result_conv = {}\n",
    "conv_model = build_base_convnet_model()\n",
    "fitted_conv_model = fit_convnet_model(conv_model, train_data, val_data)\n",
    "result_conv[drop_rate] = fitted_resnet50_mod.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.5000000000000001: [0.30659523606300354, 0.9650766849517822]}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 2s 49ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[<tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "       0, 1, 1, 0, 1, 0, 1, 1, 0, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "       0, 0, 0, 1, 0, 0, 1, 1, 1, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "       1, 0, 1, 0, 0, 1, 0, 1, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 0, 0, 1, 0, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 0, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 1, 0, 1, 0, 1, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0])>, <tf.Tensor: shape=(22,), dtype=int32, numpy=array([1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1])>]\n",
      "[[298  20]\n",
      " [ 21 835]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 23.52222222222222, 'Prediction'),\n",
       " Text(50.72222222222221, 0.5, 'True Value')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "labels = ['NORMAL', 'PNEUMONIA']\n",
    "predictions = fitted_resnet50_mod.predict(test_data)\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over the dataset\n",
    "for image_batch, label_batch in test_data:   # use dataset.unbatch() with repeat\n",
    "   # append true labels\n",
    "   y_true.append(label_batch)\n",
    "   # compute predictions\n",
    "   preds = fitted_resnet50_mod.predict(image_batch)\n",
    "   # append predicted labels\n",
    "   y_pred.append(np.where(preds > 0.5, 1,0))\n",
    "\n",
    "print(y_true)\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "true_labels = tf.concat([item for item in y_true], axis = 0)\n",
    "predicted_labels = tf.concat([item for item in y_pred], axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "print(cm)\n",
    "plt.figure(figsize = (10,10))\n",
    "ax = sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = labels,yticklabels = labels)\n",
    "ax.set(xlabel= \"Prediction\", ylabel = \"True Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 2s 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9996836 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       ...,\n",
       "       [0.99998164],\n",
       "       [1.        ],\n",
       "       [1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_resnet50_mod.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "    Normal(Class 0)       0.93      0.94      0.94       318\n",
      "Pneumonia (Class 1)       0.98      0.98      0.98       856\n",
      "\n",
      "           accuracy                           0.97      1174\n",
      "          macro avg       0.96      0.96      0.96      1174\n",
      "       weighted avg       0.97      0.97      0.97      1174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report(true_labels,predicted_labels)\n",
    "print(classification_report(true_labels, predicted_labels, target_names = ['Normal(Class 0)','Pneumonia (Class 1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor([0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 0 1 0 0 1 1 1 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor([0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor([0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor([0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor([1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1], shape=(32,), dtype=int32)\n",
      "tf.Tensor([0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1], shape=(22,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x,y in test_data:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3512 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "check_data = keras.utils.image_dataset_from_directory(\n",
    "    'D:\\\\Paul_Backup\\\\paulj\\\\Pneumonia-Classification\\\\src\\\\data_split\\\\train',\n",
    "\n",
    "    batch_size=32, \n",
    "    seed = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(32, 256, 256, 3)\n",
      "(24, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "for x,y in check_data:\n",
    "    print(x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec691a19967da4d9de78f50ff8ff93098c175cbc1d9f273cfd57fe88badd9f1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
